{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import urllib\n",
    "import math\n",
    "import random\n",
    "import collections\n",
    "import string\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading labeled data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def parseLabeledData(path):\n",
    "    file=open(path, 'r')\n",
    "    dataList = []\n",
    "    for line in csv.reader(file):\n",
    "        if len(line) == 4:\n",
    "            dataList.append(\n",
    "                {\"asin\":line[0], \n",
    "                 \"question\":line[1],\n",
    "                 \"review\":line[2],\n",
    "                 \"label\":line[3]}\n",
    "            )     \n",
    "    return dataList\n",
    "        \n",
    "\n",
    "print(\"Reading labeled data...\")\n",
    "data = parseLabeledData(R\"C:\\Users\\Moi\\Downloads\\out.csv\")\n",
    "queries = [d['question'] for d in data]\n",
    "reviews = [d['review'] for d in data]\n",
    "labels = [d['label'] for d in data]\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading all reviews & all questions...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def parseAllQueries(path):\n",
    "    file = open(path, 'r')\n",
    "    dataList = defaultdict(lambda: [])\n",
    "    for line in file:\n",
    "        line = eval(line)\n",
    "        dataList[line[\"asin\"]].append(line[\"question\"])\n",
    "      \n",
    "    return dataList\n",
    "\n",
    "def parseAllReviews(path):\n",
    "    file = open(path, 'r')\n",
    "    dataList = defaultdict(lambda: [])\n",
    "    for line in file:\n",
    "        line = eval(line)\n",
    "        dataList[line[\"asin\"]].append(line[\"reviewText\"])\n",
    "      \n",
    "    return dataList\n",
    "\n",
    "print(\"Reading all reviews & all questions...\")\n",
    "allReviews = parseAllReviews(R\"C:\\Users\\Moi\\Downloads/reviews.json\")\n",
    "allQuestions = parseAllQueries(R\"C:\\Users\\Moi\\Downloads/qa.json\")\n",
    "\n",
    "# do we have to remove questions that have no reviews or reviews that have no questions??\n",
    "docSet = [review for review in allReviews] + [question for question in allQuestions]\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findCommonWords():\n",
    "    allWords = defaultdict(int)\n",
    "    for r in allReviews.values():\n",
    "        for review in r:\n",
    "            exclude = set(string.punctuation)\n",
    "            review = ''.join(ch for ch in review if ch not in exclude)\n",
    "            for w in review.lower().split():\n",
    "                allWords[w] += 1\n",
    "\n",
    "    for q in allQuestions.values():\n",
    "        for question in q:\n",
    "            exclude = set(string.punctuation)\n",
    "            question = ''.join(ch for ch in question if ch not in exclude)\n",
    "            for w in question.lower().split():\n",
    "                allWords[w] += 1\n",
    "    \n",
    "    \n",
    "    return sorted(allWords, key=lambda x: -allWords[x])[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonWords = findCommonWords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @param a word whose frequency in the document we are calculating\n",
    "# @param document a string of a review or a question\n",
    "# @return the frequency of term in document div length of document\n",
    "\n",
    "def tf(term, document):\n",
    "    count = collections.defaultdict(int)\n",
    "    for word in document.split():\n",
    "        count[word] += 1\n",
    "\n",
    "    return count[term]/len(document.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(term):\n",
    "    count = 0         \n",
    "    for doc in docSet:\n",
    "        if term in doc.lower():\n",
    "            count += 1\n",
    "    return math.log(len(docSet)/(count+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordToIndex(term):\n",
    "    if term in commonWords:\n",
    "        return commonWords.index(term)\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(review, question):\n",
    "    review = review.lower()\n",
    "    review = ''.join([c for c in review if not (c in string.punctuation)])\n",
    "    \n",
    "    featReview = [0]*1000\n",
    "    \n",
    "    for term in review.split():\n",
    "        index = wordToIndex(term)\n",
    "        if index != -1:\n",
    "            featReview[index] += 1\n",
    "            \n",
    "    question = question.lower()\n",
    "    question = ''.join([c for c in question if not (c in string.punctuation)])\n",
    "    \n",
    "    featQuestion = [0]*1000\n",
    "    \n",
    "    for term in question.split():\n",
    "        index = wordToIndex(term)\n",
    "        if index != -1:\n",
    "            featQuestion[index] += 1\n",
    "            \n",
    "    return [a*b for a,b in zip(featQuestion,featReview)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constrain(elem):\n",
    "    if elem[0] > 0.5: return [1]\n",
    "    else: return [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.83986361]]\n",
      "[[-0.31605556]]\n"
     ]
    }
   ],
   "source": [
    "def linearRegression():\n",
    "    X = [feature(d[\"review\"], d[\"question\"]) for d in data]\n",
    "    y = [1 if l == \"y\" else 0 for l in labels]\n",
    "    \n",
    "    keys = list(range(1, len(labels)))\n",
    "    points = dict(zip(keys, zip(X, y)))\n",
    "    random.shuffle(keys)\n",
    "    X = [points[key][0] for key in keys]\n",
    "    y = [points[key][1] for key in keys]\n",
    "    \n",
    "    X_train = X[:len(X)//2]\n",
    "    y_train = y[:len(y)//2]\n",
    "    \n",
    "    X_test = X[len(X)//2:]\n",
    "    y_test = y[len(y)//2:]\n",
    "    \n",
    "    theta,residuals,rank,s = numpy.linalg.lstsq(X_train, y_train, rcond=None)\n",
    "    \n",
    "    X_train = numpy.matrix(X_train)\n",
    "    y_train = numpy.matrix(y_train).T\n",
    "    theta = numpy.matrix(theta).T\n",
    "    y_hatTrain = X_train * theta\n",
    "    \n",
    "    X_test = numpy.matrix(X_test)\n",
    "    y_test = numpy.matrix(y_test).T\n",
    "    y_hatTest = X_test * theta\n",
    "    \n",
    "    # Find mean of Training and Test\n",
    "    y_barTrain = (sum(y_train) / len(y_train))\n",
    "    y_barTest = (sum(y_test) / len(y_test))\n",
    "    \n",
    "    \n",
    "    # Constrain y_hat\n",
    "    y_hatTrainTemp = []\n",
    "    for y_star in y_hatTrain.tolist():\n",
    "        y_hatTrainTemp.append(constrain(y_star))\n",
    "    y_hatTrain = numpy.array(y_hatTrainTemp)\n",
    "    \n",
    "    y_hatTestTemp = []\n",
    "    for y_star in y_hatTest.tolist():\n",
    "        y_hatTestTemp.append(constrain(y_star))\n",
    "    y_hatTest = numpy.array(y_hatTestTemp)\n",
    "    \n",
    "    y_trainTemp = []\n",
    "    for y_star in y_train.tolist():\n",
    "        y_trainTemp.append(constrain(y_star))\n",
    "    y_train = numpy.array(y_trainTemp)\n",
    "    \n",
    "    y_testTemp = []\n",
    "    for y_star in y_test.tolist():\n",
    "        y_testTemp.append(constrain(y_star))\n",
    "    y_test = numpy.array(y_testTemp)\n",
    "    \n",
    "    # MSE for Training and Test\n",
    "    #mseTrain = ((y_hatTrain - y_train)**2).mean()\n",
    "    #print(mseTrain)\n",
    "    \n",
    "    #mseTest = ((y_hatTest - y_test)**2).mean()\n",
    "    #print(mseTest)\n",
    "    \n",
    "    #print(y_hatTrain - y_barTrain)\n",
    "    #print(numpy.square(y_hatTrain - y_barTrain))\n",
    "    \n",
    "    sstot = sum(numpy.square(y_train - y_barTrain))\n",
    "    ssreg = sum(numpy.square(y_hatTrain - y_barTrain))\n",
    "    ssres = sum(numpy.square(y_train - y_hatTrain))\n",
    "    r2 = 1 - ssres/sstot\n",
    "    #print(ssres, ssreg, ssres + ssreg, sstot)\n",
    "    print(r2)\n",
    "    \n",
    "    sstot = sum(numpy.square(y_test - y_barTest))\n",
    "    ssreg = sum(numpy.square(y_hatTest - y_barTest))\n",
    "    ssres = sum(numpy.square(y_test - y_hatTest))\n",
    "    \n",
    "    #print(ssres, ssreg, ssres + ssreg, sstot)\n",
    "    r2 = 1 - ssres/sstot\n",
    "    print(r2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "linearRegression()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
