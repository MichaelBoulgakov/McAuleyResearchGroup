{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import urllib\n",
    "import math\n",
    "import random\n",
    "import collections\n",
    "import string\n",
    "import csv\n",
    "import sys\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "import sklearn.metrics\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading labeled data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def parseLabeledData(path):\n",
    "    file=open(path, 'r')\n",
    "    dataList = []\n",
    "    for line in csv.reader(file):        \n",
    "        if len(line) >= 5:\n",
    "            dataList.append(\n",
    "                {\"asin\":line[0], \n",
    "                 \"question\":line[1],\n",
    "                 \"review\":line[2],\n",
    "                 \"answer\":line[3],\n",
    "                 \"label\":line[4]}\n",
    "            )     \n",
    "    return dataList\n",
    "        \n",
    "\n",
    "print(\"Reading labeled data...\")\n",
    "data = parseLabeledData(\"C:/Users/Moi/Downloads/out.csv\")\n",
    "queries = [d['question'] for d in data]\n",
    "answers = [d['answer'] for d in data]\n",
    "reviews = [d['review'] for d in data]\n",
    "labels = [d['label'] for d in data]\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading all reviews & all questions...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def parseAllQueries(path):\n",
    "    file = open(path, 'r')\n",
    "    dataList = defaultdict(lambda: [])\n",
    "    for line in file:\n",
    "        line = eval(line)\n",
    "        dataList[line[\"asin\"]].append(line)\n",
    "      \n",
    "    return dataList\n",
    "\n",
    "def parseAllReviews(path):\n",
    "    file = open(path, 'r')\n",
    "    dataList = defaultdict(lambda: [])\n",
    "    for line in file:\n",
    "        line = eval(line)\n",
    "        dataList[line[\"asin\"]].append(line)\n",
    "      \n",
    "    return dataList\n",
    "\n",
    "print(\"Reading all reviews & all questions...\")\n",
    "allReviews = parseAllReviews(\"C:/Users/Moi/Downloads/reviews.json\")\n",
    "allQuestions = parseAllQueries(\"C:/Users/Moi/Downloads/qa.json\")\n",
    "\n",
    "# do we have to remove questions that have no reviews or reviews that have no questions??\n",
    "docSet = []\n",
    "for entry in allReviews.values():\n",
    "    for review in entry:\n",
    "        docSet.append(review[\"reviewText\"])\n",
    "\n",
    "for entry in allQuestions.values():\n",
    "    for question in entry:\n",
    "        docSet.append(question[\"question\"])\n",
    "\n",
    "docLen = [len(d.split()) for d in docSet]\n",
    "avgdl = sum(docLen) / len(docLen)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def parse(path):\n",
    "  file = open(path, 'r')\n",
    "  for l in file:\n",
    "    yield eval(l)\n",
    "\n",
    "print(\"Reading data...\")\n",
    "products = list(parse(\"C:/Users/Moi/Downloads/reviews.json\"))\n",
    "# http://jmcauley.ucsd.edu/data/amazon/qa/qa_Tools_and_Home_Improvement.json.gz\n",
    "allQuestionsText = list(parse(\"C:/Users/Moi/Downloads/qa.json\"))\n",
    "allReviewsText = defaultdict(lambda: [])\n",
    "for product in products:\n",
    "    allReviewsText[product[\"asin\"]].append(product[\"reviewText\"])\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countAllWords():\n",
    "    allWords = defaultdict(int)\n",
    "    englishStopWords = stopwords.words('english')\n",
    "    for r in allReviews.values():\n",
    "        for review in r:\n",
    "            review = review[\"reviewText\"]\n",
    "            exclude = set(string.punctuation)\n",
    "            review = ''.join(ch for ch in review if ch not in exclude)\n",
    "            for w in review.lower().split():\n",
    "                if w not in englishStopWords:\n",
    "                    allWords[w] += 1\n",
    "\n",
    "    for q in allQuestions.values():\n",
    "        for question in q:\n",
    "            question = question[\"question\"]\n",
    "            exclude = set(string.punctuation)\n",
    "            question = ''.join(ch for ch in question if ch not in exclude)\n",
    "            for w in question.lower().split():\n",
    "                if w not in englishStopWords:\n",
    "                    allWords[w] += 1\n",
    "    \n",
    "    \n",
    "    return allWords\n",
    "\n",
    "allWords = countAllWords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonWords = sorted(allWords, key=lambda x: -allWords[x])[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idfDict = defaultdict(float)\n",
    "#for word in commonWords:\n",
    "#    count = 0         \n",
    "#    for doc in docSet:\n",
    "#        if word in doc.lower():\n",
    "#            count += 1\n",
    "#    idfScore = math.log(len(docSet)/(count+1))\n",
    "#     \n",
    "#    idfDict[word] = idfScore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @param a word whose frequency in the document we are calculating\n",
    "# @param document a string of a review or a question\n",
    "# @return the frequency of term in document div length of document\n",
    "\n",
    "def tf(term, document):\n",
    "    count = collections.defaultdict(int)\n",
    "    exclude = set(string.punctuation)\n",
    "    document = ''.join(ch for ch in document if ch not in exclude)\n",
    "    for word in document.split():\n",
    "        count[word] += 1\n",
    "\n",
    "    return count[term]/(len(document.split()) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfDict = defaultdict(float)\n",
    "\n",
    "def idf(term):\n",
    "    term = term.lower()\n",
    "    if (term in idfDict):\n",
    "        return idfDict[term]\n",
    "\n",
    "    count = 0\n",
    "    for doc in docSet:\n",
    "        #exclude = set(string.punctuation)\n",
    "        #doc = ''.join(ch for ch in doc if ch not in exclude)\n",
    "        if term in doc.lower():\n",
    "            count += 1\n",
    "        \n",
    "    idfScore = math.log(1 + len(docSet) / (count+1))\n",
    "    idfDict[term] = idfScore\n",
    "    return idfScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "okapidict = {}\n",
    "\n",
    "def OkapiBM25(review, question, k1, b):\n",
    "    if ((review, question, k1, b) in okapidict):\n",
    "        return okapidict[review, question, k1, b]\n",
    "    \n",
    "    question = question.lower()\n",
    "    question = ''.join([c for c in question if not (c in string.punctuation)])\n",
    "    \n",
    "    score = 0\n",
    "    for q in question.split():\n",
    "        num = tf(q, review) * (k1 + 1)\n",
    "        den = tf(q, review) + k1 * (1 - b + b*len(review.split()) / avgdl) \n",
    "        score += idf(q) * num / den\n",
    "        \n",
    "    #print(score, review, question)\n",
    "    okapidict[review, question, k1, b] = score\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfdict = {}\n",
    "\n",
    "def tfidf(document):\n",
    "    if (document in tfidfdict):\n",
    "        return tfidfdict[document]\n",
    "    \n",
    "    doc = document.lower()\n",
    "    doc = ''.join([c for c in doc if not (c in string.punctuation)])\n",
    "        \n",
    "    feat = collections.defaultdict(int)\n",
    "    for term in doc.split():\n",
    "        tfscore = tf(term, doc)\n",
    "        idfscore = idf(term)\n",
    "        feat[term] = tfscore * idfscore\n",
    "        \n",
    "    tfidfdict[document] = feat\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordToIndex(term):\n",
    "    if term in commonWords:\n",
    "        return commonWords.index(term)\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numCommonWords(review, question):\n",
    "    review = review.lower()\n",
    "    review = ''.join([c for c in review if not (c in string.punctuation)])\n",
    "    \n",
    "    question = question.lower()\n",
    "    question = ''.join([c for c in question if not (c in string.punctuation)])\n",
    "    \n",
    "    filtered_words = [word for word in question.split() if word not in stopwords.words('english')]\n",
    "    words = set(filtered_words)\n",
    "    \n",
    "    num = 0\n",
    "    for word in words:        \n",
    "        if word in review:\n",
    "            num += 1\n",
    "  \n",
    "    #print(num)\n",
    "    return num\n",
    "\n",
    "#numCommonWords(\"This is a red and blue review about a car\", \"I am, a BLUE and yellow quESTION about a car!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lengthDiff(review, question):\n",
    "    return abs(len(review.split()) - len(question.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# queryFeat is a feature vector for the query and reviewFeat is the feature vector for the review\n",
    "def cosineSimilarity(queryFeat, reviewFeat):\n",
    "    # Find the words the 2 dictionaries have in common\n",
    "    querySet = set(queryFeat.keys())\n",
    "    reviewSet = set(reviewFeat.keys())\n",
    "    allWords = querySet.union(reviewSet)\n",
    "    \n",
    "    # Find the cosine similarity\n",
    "    numerator = 0\n",
    "    mag1 = 0\n",
    "    mag2 = 0\n",
    "    for word in allWords:\n",
    "        numerator = numerator + queryFeat[word] * reviewFeat[word]\n",
    "        mag1 = mag1 + queryFeat[word]**2\n",
    "        mag2 = mag2 + reviewFeat[word]**2\n",
    "    if mag1 > 0 and mag2 > 0:\n",
    "        return (numerator/((mag1*mag2)**0.5))\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniqueWords(review, question, num):\n",
    "    exclude = set(string.punctuation)\n",
    "    question = ''.join(ch for ch in question if ch not in exclude)\n",
    "    review = ''.join(ch for ch in review if ch not in exclude)\n",
    "    review = review.lower()\n",
    "    \n",
    "    qFreq = {word : allWords[word] for word in question.lower().split()}\n",
    "    \n",
    "    topUnique = [word for word in sorted(qFreq, key=lambda x: qFreq[x]) if allWords[word] != 0]\n",
    "    \n",
    "    if num <= len(topUnique):\n",
    "        topUnique = topUnique[:num]\n",
    "    else:\n",
    "        topUnique += [''] * (num - len(topUnique))\n",
    "    \n",
    "    #print(qFreq)\n",
    "    #print(topUnique)\n",
    "    \n",
    "    feat = []\n",
    "    for word in topUnique:\n",
    "        #feat.append(review.split().count(word))\n",
    "        feat.append(1 if word in review and word != '' else 0)\n",
    "        \n",
    "    return feat\n",
    "\n",
    "#uniqueWords(\"The color of this item is RED red red Great\", \"Hello, this color ReD? I think great\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constrain(elems, point):    \n",
    "    for elem in elems:\n",
    "        if (elem > point): yield 1\n",
    "        else: yield 0\n",
    "        #if elem > 1: yield 1\n",
    "        #elif elem < 0: yield 0\n",
    "        #else: yield elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(featList):\n",
    "    \n",
    "    max = 0\n",
    "    min = float('inf')\n",
    "    for feat in featList:\n",
    "        if feat > max: max = feat\n",
    "        if feat < min: min = feat        \n",
    "    \n",
    "    for i in range(0,len(featList)-1):\n",
    "        if (max - min) == 0: \n",
    "            max = 1\n",
    "            min = 0\n",
    "        featList[i] = (featList[i] - min) / (max - min)\n",
    "\n",
    "    return featList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_tfidf(review, question):\n",
    "    feat = [1]\n",
    "    feat.append(cosineSimilarity(tfidf(review), tfidf(question)))\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_okapi(review, question):\n",
    "    feat = [1] \n",
    "    feat.append(OkapiBM25(review, question, 1.5, 0.75))\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(review, question, length):\n",
    "    feat = [1]\n",
    "    \n",
    "    #number of Common Words\n",
    "    #difference in length\n",
    "    #length of review\n",
    "    #length of question\n",
    "    feat.append(numCommonWords(review, question))\n",
    "    #feat.append(lengthDiff(review,question))\n",
    "    #feat.append(len(review.split()))\n",
    "    #feat.append(len(question.split()))\n",
    "    cosine = cosineSimilarity(tfidf(review), tfidf(question))\n",
    "    feat.append(cosine)\n",
    "    feat.append(OkapiBM25(review, question, 1.5, 0.75))\n",
    "    feat = feat + uniqueWords(review, question, length)\n",
    "    \n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model looking at 0 unique words:\n",
      "-2.5 :\t 0.14, 0.14, 1.00 \t 0.24, 0.23, 1.00\n",
      "-2.45 :\t 0.34, 0.17, 1.00 \t 0.42, 0.28, 1.00\n",
      "-2.4 :\t 0.39, 0.18, 1.00 \t 0.48, 0.30, 0.98\n",
      "-2.35 :\t 0.43, 0.19, 0.99 \t 0.51, 0.32, 0.98\n",
      "-2.3 :\t 0.46, 0.20, 0.99 \t 0.52, 0.32, 0.98\n",
      "-2.25 :\t 0.46, 0.20, 0.99 \t 0.52, 0.32, 0.98\n",
      "-2.2 :\t 0.46, 0.20, 0.99 \t 0.52, 0.32, 0.98\n",
      "-2.15 :\t 0.53, 0.22, 0.97 \t 0.60, 0.36, 0.98\n",
      "-2.1 :\t 0.57, 0.23, 0.91 \t 0.65, 0.39, 0.95\n",
      "-2.05 :\t 0.62, 0.25, 0.88 \t 0.69, 0.42, 0.90\n",
      "-2.0 :\t 0.65, 0.25, 0.78 \t 0.70, 0.42, 0.86\n",
      "-1.95 :\t 0.66, 0.25, 0.75 \t 0.71, 0.43, 0.86\n",
      "-1.9 :\t 0.67, 0.26, 0.75 \t 0.72, 0.44, 0.86\n",
      "-1.85 :\t 0.69, 0.26, 0.71 \t 0.72, 0.45, 0.84\n",
      "-1.8 :\t 0.72, 0.28, 0.68 \t 0.76, 0.48, 0.81\n",
      "-1.75 :\t 0.73, 0.27, 0.59 \t 0.76, 0.49, 0.79\n",
      "-1.7 :\t 0.74, 0.27, 0.57 \t 0.78, 0.51, 0.72\n",
      "-1.65 :\t 0.75, 0.29, 0.57 \t 0.77, 0.49, 0.66\n",
      "-1.6 :\t 0.76, 0.29, 0.55 \t 0.76, 0.47, 0.57\n",
      "-1.55 :\t 0.76, 0.30, 0.52 \t 0.77, 0.50, 0.53\n",
      "-1.5 :\t 0.78, 0.30, 0.46 \t 0.75, 0.44, 0.40\n",
      "-1.45 :\t 0.80, 0.33, 0.43 \t 0.75, 0.43, 0.34\n",
      "-1.4 :\t 0.81, 0.35, 0.42 \t 0.74, 0.42, 0.33\n",
      "-1.35 :\t 0.81, 0.34, 0.39 \t 0.74, 0.42, 0.33\n",
      "-1.3 :\t 0.82, 0.36, 0.39 \t 0.74, 0.41, 0.31\n",
      "-1.25 :\t 0.82, 0.35, 0.33 \t 0.75, 0.42, 0.29\n",
      "-1.2 :\t 0.84, 0.37, 0.29 \t 0.75, 0.42, 0.26\n",
      "-1.15 :\t 0.84, 0.37, 0.26 \t 0.77, 0.50, 0.26\n",
      "-1.1 :\t 0.84, 0.38, 0.26 \t 0.78, 0.52, 0.24\n",
      "-1.05 :\t 0.84, 0.36, 0.22 \t 0.77, 0.50, 0.22\n",
      "-1.0 :\t 0.84, 0.35, 0.20 \t 0.78, 0.52, 0.22\n",
      "-0.95 :\t 0.85, 0.38, 0.16 \t 0.79, 0.60, 0.21\n",
      "-0.9 :\t 0.85, 0.38, 0.14 \t 0.78, 0.53, 0.16\n",
      "-0.85 :\t 0.85, 0.33, 0.12 \t 0.79, 0.70, 0.12\n",
      "-0.8 :\t 0.85, 0.32, 0.10 \t 0.78, 0.67, 0.10\n",
      "-0.75 :\t 0.85, 0.33, 0.10 \t 0.78, 0.67, 0.10\n",
      "-0.7 :\t 0.86, 0.38, 0.09 \t 0.78, 0.67, 0.10\n",
      "-0.65 :\t 0.86, 0.38, 0.07 \t 0.78, 0.62, 0.09\n",
      "-0.6 :\t 0.86, 0.30, 0.04 \t 0.78, 0.62, 0.09\n",
      "-0.55 :\t 0.86, 0.38, 0.04 \t 0.78, 0.57, 0.07\n",
      "-0.5 :\t 0.86, 0.29, 0.03 \t 0.78, 0.57, 0.07\n",
      "-0.45 :\t 0.86, 0.29, 0.03 \t 0.78, 0.67, 0.07\n",
      "-0.4 :\t 0.86, 0.20, 0.01 \t 0.78, 0.67, 0.07\n",
      "-0.35 :\t 0.86, 0.20, 0.01 \t 0.79, 1.00, 0.07\n",
      "-0.3 :\t 0.86, 0.20, 0.01 \t 0.79, 1.00, 0.07\n",
      "-0.25 :\t 0.86, 0.25, 0.01 \t 0.79, 1.00, 0.07\n",
      "-0.2 :\t 0.86, 0.25, 0.01 \t 0.79, 1.00, 0.07\n",
      "-0.15 :\t 0.86, 0.33, 0.01 \t 0.78, 1.00, 0.05\n",
      "-0.1 :\t 0.86, 0.33, 0.01 \t 0.78, 1.00, 0.05\n",
      "-0.05 :\t 0.86, 0.00, 0.00 \t 0.78, 1.00, 0.05\n",
      "\n",
      "Our model looking at 1 unique words:\n",
      "-2.5 :\t 0.46, 0.20, 0.99 \t 0.52, 0.32, 0.98\n",
      "-2.45 :\t 0.46, 0.20, 0.99 \t 0.52, 0.32, 0.98\n",
      "-2.4 :\t 0.49, 0.21, 0.97 \t 0.57, 0.34, 0.98\n",
      "-2.35 :\t 0.55, 0.22, 0.93 \t 0.64, 0.38, 0.97\n",
      "-2.3 :\t 0.58, 0.23, 0.90 \t 0.68, 0.41, 0.93\n",
      "-2.25 :\t 0.62, 0.24, 0.83 \t 0.69, 0.42, 0.91\n",
      "-2.2 :\t 0.63, 0.25, 0.83 \t 0.70, 0.43, 0.91\n",
      "-2.15 :\t 0.64, 0.25, 0.83 \t 0.72, 0.44, 0.91\n",
      "-2.1 :\t 0.66, 0.26, 0.78 \t 0.73, 0.45, 0.88\n",
      "-2.05 :\t 0.69, 0.27, 0.72 \t 0.75, 0.48, 0.84\n",
      "-2.0 :\t 0.70, 0.28, 0.72 \t 0.78, 0.51, 0.81\n",
      "-1.95 :\t 0.71, 0.28, 0.71 \t 0.77, 0.50, 0.78\n",
      "-1.9 :\t 0.72, 0.29, 0.71 \t 0.76, 0.48, 0.72\n",
      "-1.85 :\t 0.73, 0.30, 0.71 \t 0.78, 0.51, 0.71\n",
      "-1.8 :\t 0.75, 0.31, 0.68 \t 0.77, 0.50, 0.62\n",
      "-1.75 :\t 0.78, 0.34, 0.67 \t 0.78, 0.51, 0.60\n",
      "-1.7 :\t 0.78, 0.35, 0.65 \t 0.77, 0.50, 0.59\n",
      "-1.65 :\t 0.78, 0.34, 0.61 \t 0.77, 0.49, 0.57\n",
      "-1.6 :\t 0.78, 0.33, 0.59 \t 0.77, 0.50, 0.57\n",
      "-1.55 :\t 0.80, 0.35, 0.57 \t 0.78, 0.52, 0.55\n",
      "-1.5 :\t 0.81, 0.37, 0.55 \t 0.81, 0.58, 0.55\n",
      "-1.45 :\t 0.81, 0.36, 0.52 \t 0.81, 0.59, 0.55\n",
      "-1.4 :\t 0.81, 0.36, 0.51 \t 0.81, 0.59, 0.55\n",
      "-1.35 :\t 0.81, 0.36, 0.51 \t 0.81, 0.60, 0.55\n",
      "-1.3 :\t 0.82, 0.37, 0.46 \t 0.82, 0.63, 0.50\n",
      "-1.25 :\t 0.82, 0.37, 0.45 \t 0.83, 0.67, 0.48\n",
      "-1.2 :\t 0.82, 0.37, 0.45 \t 0.83, 0.68, 0.47\n",
      "-1.15 :\t 0.82, 0.37, 0.45 \t 0.83, 0.68, 0.47\n",
      "-1.1 :\t 0.84, 0.42, 0.45 \t 0.83, 0.69, 0.47\n",
      "-1.05 :\t 0.85, 0.42, 0.35 \t 0.83, 0.72, 0.40\n",
      "-1.0 :\t 0.85, 0.43, 0.33 \t 0.83, 0.72, 0.40\n",
      "-0.95 :\t 0.85, 0.45, 0.33 \t 0.83, 0.72, 0.40\n",
      "-0.9 :\t 0.86, 0.46, 0.33 \t 0.83, 0.74, 0.40\n",
      "-0.85 :\t 0.86, 0.47, 0.33 \t 0.83, 0.74, 0.40\n",
      "-0.8 :\t 0.86, 0.46, 0.26 \t 0.84, 0.79, 0.40\n",
      "-0.75 :\t 0.86, 0.49, 0.25 \t 0.83, 0.77, 0.34\n",
      "-0.7 :\t 0.86, 0.50, 0.23 \t 0.82, 0.78, 0.31\n",
      "-0.65 :\t 0.86, 0.50, 0.23 \t 0.82, 0.77, 0.29\n",
      "-0.6 :\t 0.86, 0.48, 0.22 \t 0.80, 0.75, 0.21\n",
      "-0.55 :\t 0.86, 0.46, 0.16 \t 0.80, 0.79, 0.19\n",
      "-0.5 :\t 0.86, 0.41, 0.13 \t 0.80, 0.77, 0.17\n",
      "-0.45 :\t 0.86, 0.43, 0.13 \t 0.80, 0.77, 0.17\n",
      "-0.4 :\t 0.86, 0.43, 0.13 \t 0.80, 0.77, 0.17\n",
      "-0.35 :\t 0.86, 0.40, 0.12 \t 0.80, 0.77, 0.17\n",
      "-0.3 :\t 0.85, 0.35, 0.09 \t 0.79, 0.73, 0.14\n",
      "-0.25 :\t 0.86, 0.38, 0.09 \t 0.80, 0.80, 0.14\n",
      "-0.2 :\t 0.85, 0.33, 0.07 \t 0.79, 0.75, 0.10\n",
      "-0.15 :\t 0.86, 0.36, 0.07 \t 0.79, 0.75, 0.10\n",
      "-0.1 :\t 0.86, 0.33, 0.06 \t 0.78, 0.67, 0.07\n",
      "-0.05 :\t 0.86, 0.33, 0.06 \t 0.78, 0.67, 0.07\n",
      "\n",
      "Our model looking at 2 unique words:\n",
      "-2.5 :\t 0.67, 0.28, 0.86 \t 0.67, 0.40, 0.88\n",
      "-2.45 :\t 0.69, 0.28, 0.84 \t 0.68, 0.40, 0.84\n",
      "-2.4 :\t 0.70, 0.29, 0.84 \t 0.67, 0.39, 0.79\n",
      "-2.35 :\t 0.71, 0.29, 0.83 \t 0.67, 0.39, 0.78\n",
      "-2.3 :\t 0.73, 0.31, 0.83 \t 0.68, 0.39, 0.71\n",
      "-2.25 :\t 0.73, 0.31, 0.81 \t 0.68, 0.38, 0.69\n",
      "-2.2 :\t 0.73, 0.31, 0.80 \t 0.67, 0.38, 0.67\n",
      "-2.15 :\t 0.74, 0.32, 0.80 \t 0.68, 0.38, 0.66\n",
      "-2.1 :\t 0.75, 0.32, 0.77 \t 0.70, 0.40, 0.66\n",
      "-2.05 :\t 0.75, 0.33, 0.77 \t 0.70, 0.40, 0.66\n",
      "-2.0 :\t 0.75, 0.33, 0.77 \t 0.70, 0.40, 0.66\n",
      "-1.95 :\t 0.76, 0.33, 0.72 \t 0.72, 0.43, 0.64\n",
      "-1.9 :\t 0.76, 0.33, 0.72 \t 0.72, 0.42, 0.62\n",
      "-1.85 :\t 0.77, 0.34, 0.72 \t 0.72, 0.42, 0.62\n",
      "-1.8 :\t 0.77, 0.34, 0.71 \t 0.72, 0.42, 0.62\n",
      "-1.75 :\t 0.77, 0.34, 0.70 \t 0.72, 0.42, 0.62\n",
      "-1.7 :\t 0.77, 0.34, 0.70 \t 0.72, 0.43, 0.62\n",
      "-1.65 :\t 0.77, 0.34, 0.70 \t 0.72, 0.43, 0.62\n",
      "-1.6 :\t 0.79, 0.35, 0.64 \t 0.73, 0.43, 0.57\n",
      "-1.55 :\t 0.80, 0.36, 0.62 \t 0.73, 0.43, 0.57\n",
      "-1.5 :\t 0.80, 0.37, 0.62 \t 0.73, 0.43, 0.57\n",
      "-1.45 :\t 0.81, 0.37, 0.62 \t 0.74, 0.44, 0.57\n",
      "-1.4 :\t 0.81, 0.38, 0.61 \t 0.73, 0.43, 0.55\n",
      "-1.35 :\t 0.81, 0.39, 0.61 \t 0.73, 0.43, 0.53\n",
      "-1.3 :\t 0.81, 0.38, 0.59 \t 0.73, 0.42, 0.52\n",
      "-1.25 :\t 0.81, 0.38, 0.58 \t 0.73, 0.43, 0.50\n",
      "-1.2 :\t 0.82, 0.39, 0.55 \t 0.75, 0.46, 0.50\n",
      "-1.15 :\t 0.82, 0.38, 0.51 \t 0.80, 0.57, 0.50\n",
      "-1.1 :\t 0.83, 0.39, 0.49 \t 0.80, 0.58, 0.50\n",
      "-1.05 :\t 0.83, 0.39, 0.49 \t 0.80, 0.58, 0.50\n",
      "-1.0 :\t 0.83, 0.41, 0.46 \t 0.80, 0.60, 0.43\n",
      "-0.95 :\t 0.84, 0.42, 0.43 \t 0.82, 0.67, 0.41\n",
      "-0.9 :\t 0.84, 0.42, 0.43 \t 0.82, 0.68, 0.40\n",
      "-0.85 :\t 0.85, 0.45, 0.43 \t 0.82, 0.70, 0.40\n",
      "-0.8 :\t 0.86, 0.50, 0.42 \t 0.83, 0.75, 0.36\n",
      "-0.75 :\t 0.87, 0.54, 0.39 \t 0.83, 0.75, 0.36\n",
      "-0.7 :\t 0.87, 0.54, 0.36 \t 0.83, 0.75, 0.36\n",
      "-0.65 :\t 0.88, 0.58, 0.36 \t 0.83, 0.77, 0.34\n",
      "-0.6 :\t 0.88, 0.61, 0.32 \t 0.84, 0.87, 0.34\n",
      "-0.55 :\t 0.88, 0.62, 0.30 \t 0.84, 0.87, 0.34\n",
      "-0.5 :\t 0.88, 0.62, 0.30 \t 0.85, 0.95, 0.34\n",
      "-0.45 :\t 0.88, 0.62, 0.29 \t 0.85, 1.00, 0.33\n",
      "-0.4 :\t 0.88, 0.62, 0.29 \t 0.84, 1.00, 0.29\n",
      "-0.35 :\t 0.88, 0.62, 0.29 \t 0.84, 1.00, 0.29\n",
      "-0.3 :\t 0.88, 0.63, 0.28 \t 0.84, 1.00, 0.29\n",
      "-0.25 :\t 0.88, 0.63, 0.28 \t 0.83, 1.00, 0.28\n",
      "-0.2 :\t 0.88, 0.63, 0.28 \t 0.83, 1.00, 0.28\n",
      "-0.15 :\t 0.88, 0.63, 0.28 \t 0.83, 1.00, 0.28\n",
      "-0.1 :\t 0.88, 0.62, 0.26 \t 0.83, 1.00, 0.28\n",
      "-0.05 :\t 0.88, 0.62, 0.26 \t 0.83, 1.00, 0.28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test(y, y_hat):\n",
    "    #print(sklearn.metrics.r2_score(y, y_hat))\n",
    "    \n",
    "    \n",
    "    accuracy = sklearn.metrics.accuracy_score(y, y_hat)\n",
    "    precision = sklearn.metrics.precision_score(y, y_hat)\n",
    "    recall = sklearn.metrics.recall_score(y, y_hat)\n",
    "    \n",
    "    return \"{0:.2f}, {1:.2f}, {2:.2f}\".format(accuracy, precision, recall)\n",
    "\n",
    "def train(X, y, breakpoint=0.15):\n",
    "    random.seed(4410)\n",
    "    \n",
    "    for j in range(0,len(X[0])):\n",
    "        featList = []\n",
    "        for i in range(0,len(X)-1):\n",
    "            featList.append(X[i][j])\n",
    "        featList = normalize(featList)\n",
    "        for i in range(0,len(X)-1):\n",
    "            X[i][j] = featList[i]\n",
    "\n",
    "    lr.fit(X, y)\n",
    "    \n",
    "    return lr\n",
    "\n",
    "lr = LogisticRegression()\n",
    "def pipeline(X, y, breakpoint=0.15):\n",
    "    random.seed(4410)\n",
    "    \n",
    "    for j in range(0,len(X[0])):\n",
    "        featList = []\n",
    "        for i in range(0,len(X)-1):\n",
    "            featList.append(X[i][j])\n",
    "        featList = normalize(featList)\n",
    "        for i in range(0,len(X)-1):\n",
    "            X[i][j] = featList[i]\n",
    "    \n",
    "    keys = list(range(1, len(labels)))\n",
    "    points = dict(zip(keys, zip(X, y)))\n",
    "    random.shuffle(keys)\n",
    "    X_rand = [points[key][0] for key in keys]\n",
    "    y_rand = [points[key][1] for key in keys]\n",
    "    \n",
    "    X_train = X[:len(X_rand)*2//3]\n",
    "    y_train = y[:len(y_rand)*2//3]\n",
    "    \n",
    "    X_test = X[len(X_rand)*2//3:]\n",
    "    y_test = y[len(y_rand)*2//3:]\n",
    "       \n",
    "    lr.fit(X_train, y_train)\n",
    "    y_hatTrain = lr.predict(X_train)\n",
    "    y_hatTest = lr.predict(X_test)\n",
    "    \n",
    "    #print(y_hatTrain)\n",
    "    \n",
    "    \n",
    "    y_confidenceTrain = lr.decision_function(X_train)\n",
    "    y_confidenceTest = lr.decision_function(X_test)\n",
    "    \n",
    "    #print(y_confidenceTrain)\n",
    "    \n",
    "\n",
    "    \n",
    "    return (y_confidenceTrain, y_confidenceTest, y_train, y_test)\n",
    "\n",
    "    \n",
    "\n",
    "for length in range(0, 3):\n",
    "    print(\"Our model looking at\", length, \"unique words:\")\n",
    "    \n",
    "    X = [feature(d[\"review\"], d[\"question\"], length) for d in data]\n",
    "    y = [1 if l == \"Y\" else 0 for l in labels]\n",
    "    y_hatTrain, y_hatTest, y_train, y_test = pipeline(X, y)\n",
    "    \n",
    "    for cutoff in range(-50, 0):\n",
    "        y_hatTrain_c = list(constrain(y_hatTrain, cutoff / 20))\n",
    "        y_hatTest_c = list(constrain(y_hatTest, cutoff / 20))\n",
    "        train_string = test(y_train, y_hatTrain_c)\n",
    "        test_string = test(y_test, y_hatTest_c)\n",
    "\n",
    "        print(cutoff / 20, \":\\t\", train_string, \"\\t\", test_string)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def questionAndReviews(qa, reviews):\n",
    "    X = []\n",
    "    dictionary = []\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for question in qa:\n",
    "        \n",
    "    #while numReviews < 70:\n",
    "        if (question['questionType'] != \"yes/no\"): continue\n",
    "        if (question['answerType'] == '?'): continue\n",
    "        #if (question['asin'] in questionSet): continue\n",
    "        questionText = question['question']\n",
    "        asin = question['asin']\n",
    "        answer = question['answerType']\n",
    "        numReviews = len(reviews[asin])\n",
    "        if (numReviews < 70): continue\n",
    "            \n",
    "                    \n",
    "        count += 1\n",
    "        \n",
    "        if (count > 500): break\n",
    "    \n",
    "        # reviewsSet is list of all review text for this product\n",
    "        reviewsSet = reviews[asin]\n",
    "        \n",
    "        questionFeat = []\n",
    "        questionDictionary = []\n",
    "        for review in reviewsSet:\n",
    "            questionFeat += [feature(review, questionText, 2)]\n",
    "            questionDictionary += [(questionText, review, asin, answer)]\n",
    "        \n",
    "        X += [questionFeat]\n",
    "        dictionary += [questionDictionary]\n",
    "\n",
    "    return (X, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "(allFeature, featureMap) = questionAndReviews(allQuestionsText,allReviewsText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Would you use this for a framing/finish nail gun? \n",
      " I use this hose primarily for my nail guns.  It is nice and heavy so it lays flat when in use.  It also winds up well unlike a pvc or plastic hose.  The ends are installed well.  This product is clearly superior to Chinese knock-offs that you may find at a big-box store.  Don't try to save $4; buy this one! \n",
      "\n",
      "I want a soft air hose so it's easy roll up and work with. My air hose is hard and hard to work with. Is this one easy to work with? Thanks. \n",
      " This hose is both sturdy and consistent. Since it is rubber it gets softer when it is up on a hot roof in the summer and it gets stiffer when it is used in freezing weather. But it resists tangling as long as I take the time to get the twist out as I unroll it. I have had no problem with soft spots, blow outs nor leaks. It has resisted the little bit of oil I've gotten on it. The fittings are solidly placed, male on one end and female on the other so I can put the ends together and keep the dirt out when not in use.And as an additional positive, though I doubt many will encounter the situation, it has so far resisted being chewed by a pair of pigmy goats which like to follow me and browse when I am working outdoors!I usually run most of my tools at a minimum pressure of 80 PSI, but there are a few of the that need 100 PSI. This hose handles those pressures well, so it should easily handle lower pressure jobs. I've bought 3 compressors in my life but my favorite isMakita MAC2400 Big Bore 2.5 HP Air Compressor. As compressors go it is quiet and light, easily carried with one hand. (Well, easy for me, maybe not for you.) \n",
      "\n",
      "Will this item work for this ? http://www.amazon.com/TEKTON-4725-Con... \n",
      " Don't listen to the negative reviews.Genuine \"GoodYear\" or not, IMO, this item is a very good deal. It looks genuine to me.Plus, it works as advertised, appears to be very durable with decent ends.A+ \n",
      "\n",
      "does it work with a 4000 model \n",
      " About a year ago we remodeled our house - new homeowner with not a lot of tools. So at that time I bought aBlack & Decker RTX-B 3-Speed RTX Rotary Tool Kit. Good tool, but the chuck was a PITA - the bit was always slipping or falling. I saw the Dremel 4486 Chuck on Amazon but did not purchase it at that time. WHAT A MISTAKE! Because after the remodeling was done (well, if you own a house you know it's never done - it's always work in progress), I slowly started to buy some of the tools that I felt I needed during the remodeling, and this chuck was one of them - what a pleasure to use! No more slipping or falling bits. I still cannot believe that what could have stopped me from all that aggravation was just 7 bucks away... \n",
      "\n",
      "Does it fit the dremel 8220? \n",
      " This Chuck fit this tool Dremel 700-N/8 miniMite  two speed Rotary, this  Tool it fit very good .(HAVE A BLESS DAY) \n",
      "\n",
      "Will this work with a Wen rotary tool, specifically the 101 piece kit here on Amazon? \n",
      " About a year ago we remodeled our house - new homeowner with not a lot of tools. So at that time I bought aBlack & Decker RTX-B 3-Speed RTX Rotary Tool Kit. Good tool, but the chuck was a PITA - the bit was always slipping or falling. I saw the Dremel 4486 Chuck on Amazon but did not purchase it at that time. WHAT A MISTAKE! Because after the remodeling was done (well, if you own a house you know it's never done - it's always work in progress), I slowly started to buy some of the tools that I felt I needed during the remodeling, and this chuck was one of them - what a pleasure to use! No more slipping or falling bits. I still cannot believe that what could have stopped me from all that aggravation was just 7 bucks away... \n",
      "\n",
      "Does this work with the Milwawkee 12v rotary tool? Amazon advertises them together \n",
      " About a year ago we remodeled our house - new homeowner with not a lot of tools. So at that time I bought aBlack & Decker RTX-B 3-Speed RTX Rotary Tool Kit. Good tool, but the chuck was a PITA - the bit was always slipping or falling. I saw the Dremel 4486 Chuck on Amazon but did not purchase it at that time. WHAT A MISTAKE! Because after the remodeling was done (well, if you own a house you know it's never done - it's always work in progress), I slowly started to buy some of the tools that I felt I needed during the remodeling, and this chuck was one of them - what a pleasure to use! No more slipping or falling bits. I still cannot believe that what could have stopped me from all that aggravation was just 7 bucks away... \n",
      "\n",
      "May I ask if this \"Dremel 4486 MultiPro Keyless Chuck\" works for Dremet multipro 3961 model? Anyone using a Dremel Multipro 3961 please let me know... \n",
      " Dremel 4486 Dremel MultiPro Keyless ChuckThe Colet system that comes with the Dremel is good in a pinch but if you are going to be using the Dremel regularly than This little beauty is a definite must \n",
      "\n",
      "WILL THIS WORK WITH MODEL #280? \n",
      " About a year ago we remodeled our house - new homeowner with not a lot of tools. So at that time I bought aBlack & Decker RTX-B 3-Speed RTX Rotary Tool Kit. Good tool, but the chuck was a PITA - the bit was always slipping or falling. I saw the Dremel 4486 Chuck on Amazon but did not purchase it at that time. WHAT A MISTAKE! Because after the remodeling was done (well, if you own a house you know it's never done - it's always work in progress), I slowly started to buy some of the tools that I felt I needed during the remodeling, and this chuck was one of them - what a pleasure to use! No more slipping or falling bits. I still cannot believe that what could have stopped me from all that aggravation was just 7 bucks away... \n",
      "\n",
      "do you have a chuck for a dremel 7300-n8 keyless chuck \n",
      " Anyone who is a hobbyist uses a dremel daily.  That means changing an attachment regularly all through the day.  This keyless chuck simple makes this job faster and easier. \n",
      "\n",
      "Will it fit on the Milwaukee brand ?? Thanks... \n",
      " Great price, Great Item, goes perfect with my orbit sander! I will be ordering a lot more, even came in a perfect organizational box that fits perfectly in most tool boxes! Thanks so much. \n",
      "\n",
      "Will it work for wood sanding? \n",
      " I think the folks that have issues with these must not understand sanding, Maybe they're trying to fold it them over a block of wood.Works perfect on my Dewalt \n",
      "\n",
      "Will these disks fit the \"DEWALT D26451 3-Amp 5-Inch Random-Orbit Sander\" I just ordered? \n",
      " I have been using these with DEWALT D26451 3-Amp 5-Inch Random-Orbit Sander and they work without a flaw ... I would certainly purchase them again \n",
      "\n",
      "Can I use this on pruning shears? \n",
      " I bought one along with a Victorinox chef's knife. I've sharpened every knife in the kitchen--including some serrated edge ones, believe it or not!  Also used it too resharpen a utility knife blade and on a garden shears. It doesn't reach all the way into the mouth of the short bladed garden shears. Maybe that's why they make a different one for scissors and the like. For every other use it is swift, easy and deadly. I've used many other types of sharpeners and never gotten such good results.Maybe the guy who says you get a better edge with a honing stone and oil is right, but this is a lot easier and more than sharp enough. Your knives will actulally be safer with a sharp edge, because you are not as likely to slip off the target. Buy this. You won't be sorry. \n",
      "\n",
      "Will this sharpen a carbon steel blade like a Ka-Bar? \n",
      " Great for Stainless Steel blades. Not good at all for Carbon Steel blades! I sharpened all of my pocket knives, & household knives with this, & it worked great! When I tried sharpening my old military (Carbon Steel) knives, I realized it seemed to be doing more harm than help. I think it simply isn't intended for hard steel. But with stainless knives, I'm very impressed! \n",
      "\n",
      "Can I install it myself, I'm not an electrician or skilled handyman? \n",
      " This is a great product and I have purchased more since then. They are easy to install and operate. Indicators are clear and loud. Battery lasted me for a long time, when it went, it indicated to me it had a low battery and I changing the battery took no longer than a few minutes. \n",
      "\n",
      "I am looking for a smoke alarm that can detect cigarette smoke, Will this one work? \n",
      " The Kiddie smoke/co2 alarm works great!  We installed both units in the same location as the old smoke detectors were located however one was in the kitchen where we had just installed a gas range; and sure enough the kitchen smoke/alarm went off (Scared my wife's dog) while I was cooking bacon and forgot to turn the exhaust fan on.  Moved the alarm to the computer room just off the kitchen and have not heard a beep from it.  We have a 1960 brick home and was not wired for alarms so we purchased the battery powered ones. \n",
      "\n",
      "I want to get this for use in the office. I hear everything from birds, keyboarding to footsteps. Earplugs are a pain. Would you recommend a pair? \n",
      " We have a couple of parrots and in the evening when they decide to yell, they drive everyone in the house crazy after a while.  I ordered a pair of these earmuffs and while we can still faintly hear them, it's a very big improvement.  If you have ever heard a macaw, you know how loud they be.  When the birds ain't happy, ain't nobody happy around here! Their yelling doesn't normally bother me, but it drives other family members crazy when they get going. The headphones would also be great for things like cutting the lawn, blowing leaves or reading in a noisy room, anything really where you want to save your ears from loud noises.I can't believe how comfortable these headphones are.  They adjust to fit your head and the foam cushions are really soft and they fit snugly so you can wear them for a long time.  Two thumbs up for a great product. \n",
      "\n",
      "Would these block out someone talking? \n",
      " Watch any TV show where people are working with noisy equipment and you will see them wearing these muffs (easy to spot with the red band) there is a reason why they have them, because they are comfortable and work!I am 28 I have been working construction for 8 years, I never wore hearing protection and just lifted my shoulder up to cover my right ear as I cut stuff. The result? An early start to hearing loss which only gets worse if I hear loud noises. I started wearing a pair of the nicer Stanley ear muffs you would find at Menards (/Stanley-RST-63007) and they were uncomfortable over a long period of time. I got the 3M ones and will not trade them for anything. They are very soft and comfortable, yes they are a bit bigger but that size means more hearing protection. They block out all soft noises, its even hard to hear someone talking. Louder noises are very faint. A must buy! \n",
      "\n",
      "Can I sleep in them? \n",
      " bought for a son whom shoots \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for features, kvpairs in zip(allFeature, featureMap):\n",
    "    y_hat = lr.decision_function(features)\n",
    "    \n",
    "    questionText = kvpairs[0][0]\n",
    "    \n",
    "    maxnum = 0\n",
    "    maxi = 0\n",
    "    for i in range(0, len(y_hat)):\n",
    "        num = y_hat[i]\n",
    "        \n",
    "        if (num > maxnum): \n",
    "            maxnum = num\n",
    "            maxi = i\n",
    "    \n",
    "    reviewText = kvpairs[maxi][1]\n",
    "    \n",
    "    print(questionText, \"\\n\", reviewText, \"\\n\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:/Users/Moi/Downloads/highestReviewData.csv\", 'w') as the_file:\n",
    "\n",
    "    for features, kvpairs in zip(allFeature, featureMap):\n",
    "        \n",
    "        y_hat = lr.decision_function(features)\n",
    "    \n",
    "        questionText = kvpairs[0][0]\n",
    "\n",
    "        maxnum = 0\n",
    "        maxi = 0\n",
    "        for i in range(0, len(y_hat)):\n",
    "            num = y_hat[i]\n",
    "\n",
    "            if (num > maxnum): \n",
    "                maxnum = num\n",
    "                maxi = i\n",
    "\n",
    "        reviewText = kvpairs[maxi][1]\n",
    "        \n",
    "        asin = kvpairs[0][2]\n",
    "        answer = kvpairs[0][3]\n",
    "        \n",
    "        the_file.write(asin)\n",
    "        the_file.write(',')\n",
    "        the_file.write(questionText.replace(',', ''))\n",
    "        the_file.write(',')\n",
    "        the_file.write(reviewText.replace(',', ''))\n",
    "        the_file.write(',')\n",
    "        the_file.write(answer.replace(',', ''))\n",
    "        the_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
