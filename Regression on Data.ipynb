{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import urllib\n",
    "import math\n",
    "import random\n",
    "import collections\n",
    "import string\n",
    "import csv\n",
    "import sys\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import svm\n",
    "import sklearn.metrics\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading labeled data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def parseLabeledData(path):\n",
    "    file=open(path, 'r')\n",
    "    dataList = []\n",
    "    for line in csv.reader(file):        \n",
    "        if len(line) >= 5:\n",
    "            dataList.append(\n",
    "                {\"asin\":line[0], \n",
    "                 \"question\":line[1],\n",
    "                 \"review\":line[2],\n",
    "                 \"answer\":line[3],\n",
    "                 \"label\":line[4]}\n",
    "            )     \n",
    "    return dataList\n",
    "        \n",
    "\n",
    "print(\"Reading labeled data...\")\n",
    "data = parseLabeledData(\"C:/Users/Moi/Downloads/out.csv\")\n",
    "queries = [d['question'] for d in data]\n",
    "answers = [d['answer'] for d in data]\n",
    "reviews = [d['review'] for d in data]\n",
    "labels = [d['label'] for d in data]\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading all reviews & all questions...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def parseAllQueries(path):\n",
    "    file = open(path, 'r')\n",
    "    dataList = defaultdict(lambda: [])\n",
    "    for line in file:\n",
    "        line = eval(line)\n",
    "        dataList[line[\"asin\"]].append(line)\n",
    "      \n",
    "    return dataList\n",
    "\n",
    "def parseAllReviews(path):\n",
    "    file = open(path, 'r')\n",
    "    dataList = defaultdict(lambda: [])\n",
    "    for line in file:\n",
    "        line = eval(line)\n",
    "        dataList[line[\"asin\"]].append(line)\n",
    "      \n",
    "    return dataList\n",
    "\n",
    "print(\"Reading all reviews & all questions...\")\n",
    "allReviews = parseAllReviews(\"C:/Users/Moi/Downloads/reviews.json\")\n",
    "allQuestions = parseAllQueries(\"C:/Users/Moi/Downloads/qa.json\")\n",
    "\n",
    "# do we have to remove questions that have no reviews or reviews that have no questions??\n",
    "docSet = []\n",
    "for entry in allReviews.values():\n",
    "    for review in entry:\n",
    "        docSet.append(review[\"reviewText\"])\n",
    "\n",
    "for entry in allQuestions.values():\n",
    "    for question in entry:\n",
    "        docSet.append(question[\"question\"])\n",
    "\n",
    "docLen = [len(d.split()) for d in docSet]\n",
    "avgdl = sum(docLen) / len(docLen)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countAllWords():\n",
    "    allWords = defaultdict(int)\n",
    "    englishStopWords = stopwords.words('english')\n",
    "    for r in allReviews.values():\n",
    "        for review in r:\n",
    "            review = review[\"reviewText\"]\n",
    "            exclude = set(string.punctuation)\n",
    "            review = ''.join(ch for ch in review if ch not in exclude)\n",
    "            for w in review.lower().split():\n",
    "                if w not in englishStopWords:\n",
    "                    allWords[w] += 1\n",
    "\n",
    "    for q in allQuestions.values():\n",
    "        for question in q:\n",
    "            question = question[\"question\"]\n",
    "            exclude = set(string.punctuation)\n",
    "            question = ''.join(ch for ch in question if ch not in exclude)\n",
    "            for w in question.lower().split():\n",
    "                if w not in englishStopWords:\n",
    "                    allWords[w] += 1\n",
    "    \n",
    "    \n",
    "    return allWords\n",
    "\n",
    "allWords = countAllWords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonWords = sorted(allWords, key=lambda x: -allWords[x])[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idfDict = defaultdict(float)\n",
    "#for word in commonWords:\n",
    "#    count = 0         \n",
    "#    for doc in docSet:\n",
    "#        if word in doc.lower():\n",
    "#            count += 1\n",
    "#    idfScore = math.log(len(docSet)/(count+1))\n",
    "#     \n",
    "#    idfDict[word] = idfScore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @param a word whose frequency in the document we are calculating\n",
    "# @param document a string of a review or a question\n",
    "# @return the frequency of term in document div length of document\n",
    "\n",
    "def tf(term, document):\n",
    "    count = collections.defaultdict(int)\n",
    "    exclude = set(string.punctuation)\n",
    "    document = ''.join(ch for ch in document if ch not in exclude)\n",
    "    for word in document.split():\n",
    "        count[word] += 1\n",
    "\n",
    "    return count[term]/(len(document.split()) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfDict = defaultdict(float)\n",
    "\n",
    "def idf(term):\n",
    "    term = term.lower()\n",
    "    if (term in idfDict):\n",
    "        return idfDict[term]\n",
    "\n",
    "    count = 0\n",
    "    for doc in docSet:\n",
    "        #exclude = set(string.punctuation)\n",
    "        #doc = ''.join(ch for ch in doc if ch not in exclude)\n",
    "        if term in doc.lower():\n",
    "            count += 1\n",
    "        \n",
    "    idfScore = math.log(1 + len(docSet) / (count+1))\n",
    "    idfDict[term] = idfScore\n",
    "    return idfScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "okapidict = {}\n",
    "\n",
    "def OkapiBM25(review, question, k1, b):\n",
    "    if ((review, question, k1, b) in okapidict):\n",
    "        return okapidict[review, question, k1, b]\n",
    "    \n",
    "    question = question.lower()\n",
    "    question = ''.join([c for c in question if not (c in string.punctuation)])\n",
    "    \n",
    "    score = 0\n",
    "    for q in question.split():\n",
    "        num = tf(q, review) * (k1 + 1)\n",
    "        den = tf(q, review) + k1 * (1 - b + b*len(review.split()) / avgdl) \n",
    "        score += idf(q) * num / den\n",
    "        \n",
    "    #print(score, review, question)\n",
    "    okapidict[review, question, k1, b] = score\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfdict = {}\n",
    "\n",
    "def tfidf(document):\n",
    "    if (document in tfidfdict):\n",
    "        return tfidfdict[document]\n",
    "    \n",
    "    doc = document.lower()\n",
    "    doc = ''.join([c for c in doc if not (c in string.punctuation)])\n",
    "        \n",
    "    feat = collections.defaultdict(int)\n",
    "    for term in doc.split():\n",
    "        tfscore = tf(term, doc)\n",
    "        idfscore = idf(term)\n",
    "        feat[term] = tfscore * idfscore\n",
    "        \n",
    "    tfidfdict[document] = feat\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordToIndex(term):\n",
    "    if term in commonWords:\n",
    "        return commonWords.index(term)\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numCommonWords(review, question):\n",
    "    review = review.lower()\n",
    "    review = ''.join([c for c in review if not (c in string.punctuation)])\n",
    "    \n",
    "    question = question.lower()\n",
    "    question = ''.join([c for c in question if not (c in string.punctuation)])\n",
    "    \n",
    "    filtered_words = [word for word in question.split() if word not in stopwords.words('english')]\n",
    "    words = set(filtered_words)\n",
    "    \n",
    "    num = 0\n",
    "    for word in words:        \n",
    "        if word in review:\n",
    "            num += 1\n",
    "  \n",
    "    #print(num)\n",
    "    return num\n",
    "\n",
    "#numCommonWords(\"This is a red and blue review about a car\", \"I am, a BLUE and yellow quESTION about a car!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lengthDiff(review, question):\n",
    "    return abs(len(review.split()) - len(question.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# queryFeat is a feature vector for the query and reviewFeat is the feature vector for the review\n",
    "def cosineSimilarity(queryFeat, reviewFeat):\n",
    "    # Find the words the 2 dictionaries have in common\n",
    "    querySet = set(queryFeat.keys())\n",
    "    reviewSet = set(reviewFeat.keys())\n",
    "    allWords = querySet.union(reviewSet)\n",
    "    \n",
    "    # Find the cosine similarity\n",
    "    numerator = 0\n",
    "    mag1 = 0\n",
    "    mag2 = 0\n",
    "    for word in allWords:\n",
    "        numerator = numerator + queryFeat[word] * reviewFeat[word]\n",
    "        mag1 = mag1 + queryFeat[word]**2\n",
    "        mag2 = mag2 + reviewFeat[word]**2\n",
    "    if mag1 > 0 and mag2 > 0:\n",
    "        return (numerator/((mag1*mag2)**0.5))\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniqueWords(review, question, num):\n",
    "    exclude = set(string.punctuation)\n",
    "    question = ''.join(ch for ch in question if ch not in exclude)\n",
    "    review = ''.join(ch for ch in review if ch not in exclude)\n",
    "    review = review.lower()\n",
    "    \n",
    "    qFreq = {word : allWords[word] for word in question.lower().split()}\n",
    "    \n",
    "    topUnique = [word for word in sorted(qFreq, key=lambda x: qFreq[x]) if allWords[word] != 0]\n",
    "    \n",
    "    if num <= len(topUnique):\n",
    "        topUnique = topUnique[:num]\n",
    "    else:\n",
    "        topUnique += [''] * (num - len(topUnique))\n",
    "    \n",
    "    #print(qFreq)\n",
    "    #print(topUnique)\n",
    "    \n",
    "    feat = []\n",
    "    for word in topUnique:\n",
    "        #feat.append(review.split().count(word))\n",
    "        feat.append(1 if word in review and word != '' else 0)\n",
    "        \n",
    "    return feat\n",
    "\n",
    "#uniqueWords(\"The color of this item is RED red red Great\", \"Hello, this color ReD? I think great\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constrain(elems, point):    \n",
    "    for elem in elems:\n",
    "        if (elem > point): yield 1\n",
    "        else: yield 0\n",
    "        #if elem > 1: yield 1\n",
    "        #elif elem < 0: yield 0\n",
    "        #else: yield elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(featList):\n",
    "    \n",
    "    max = 0\n",
    "    min = float('inf')\n",
    "    for feat in featList:\n",
    "        if feat > max: max = feat\n",
    "        if feat < min: min = feat        \n",
    "    \n",
    "    for i in range(0,len(featList)-1):\n",
    "        if (max - min) == 0: \n",
    "            max = 1\n",
    "            min = 0\n",
    "        featList[i] = (featList[i] - min) / (max - min)\n",
    "\n",
    "    return featList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_tfidf(review, question):\n",
    "    feat = [1]\n",
    "    feat.append(cosineSimilarity(tfidf(review), tfidf(question)))\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_okapi(review, question):\n",
    "    feat = [1] \n",
    "    feat.append(OkapiBM25(review, question, 1.5, 0.75))\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(review, question, length):\n",
    "    feat = [1]\n",
    "    \n",
    "    #number of Common Words\n",
    "    #difference in length\n",
    "    #length of review\n",
    "    #length of question\n",
    "    feat.append(numCommonWords(review, question))\n",
    "    #feat.append(lengthDiff(review,question))\n",
    "    #feat.append(len(review.split()))\n",
    "    #feat.append(len(question.split()))\n",
    "    cosine = cosineSimilarity(tfidf(review), tfidf(question))\n",
    "    feat.append(cosine)\n",
    "    feat.append(OkapiBM25(review, question, 1.5, 0.75))\n",
    "    feat = feat + uniqueWords(review, question, length)\n",
    "    \n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model looking at 0 unique words:\n",
      "0.0 :\t 0.14, 0.14, 1.00 \t 0.24, 0.23, 1.00\n",
      "0.05 :\t 0.40, 0.18, 0.99 \t 0.47, 0.30, 0.98\n",
      "0.1 :\t 0.57, 0.24, 0.96 \t 0.64, 0.38, 0.97\n",
      "0.15 :\t 0.69, 0.27, 0.74 \t 0.74, 0.46, 0.84\n",
      "0.2 :\t 0.76, 0.30, 0.58 \t 0.79, 0.53, 0.67\n",
      "0.25 :\t 0.81, 0.35, 0.42 \t 0.77, 0.50, 0.43\n",
      "0.3 :\t 0.86, 0.46, 0.28 \t 0.78, 0.52, 0.26\n",
      "0.35 :\t 0.86, 0.42, 0.14 \t 0.79, 0.64, 0.16\n",
      "0.4 :\t 0.86, 0.36, 0.07 \t 0.80, 0.88, 0.12\n",
      "0.45 :\t 0.86, 0.50, 0.06 \t 0.79, 1.00, 0.09\n",
      "\n",
      "Our model looking at 1 unique words:\n",
      "0.0 :\t 0.14, 0.14, 1.00 \t 0.24, 0.23, 1.00\n",
      "0.05 :\t 0.45, 0.20, 0.99 \t 0.51, 0.31, 0.98\n",
      "0.1 :\t 0.63, 0.26, 0.93 \t 0.70, 0.43, 0.93\n",
      "0.15 :\t 0.72, 0.29, 0.74 \t 0.78, 0.52, 0.84\n",
      "0.2 :\t 0.77, 0.33, 0.64 \t 0.77, 0.50, 0.59\n",
      "0.25 :\t 0.83, 0.41, 0.57 \t 0.80, 0.57, 0.55\n",
      "0.3 :\t 0.85, 0.43, 0.38 \t 0.83, 0.69, 0.43\n",
      "0.35 :\t 0.86, 0.46, 0.25 \t 0.83, 0.77, 0.34\n",
      "0.4 :\t 0.86, 0.44, 0.16 \t 0.81, 0.81, 0.22\n",
      "0.45 :\t 0.86, 0.44, 0.10 \t 0.79, 0.75, 0.10\n",
      "\n",
      "Our model looking at 2 unique words:\n",
      "0.0 :\t 0.14, 0.14, 1.00 \t 0.24, 0.23, 1.00\n",
      "0.05 :\t 0.55, 0.23, 0.97 \t 0.60, 0.36, 0.97\n",
      "0.1 :\t 0.69, 0.29, 0.84 \t 0.68, 0.40, 0.81\n",
      "0.15 :\t 0.75, 0.33, 0.78 \t 0.69, 0.39, 0.66\n",
      "0.2 :\t 0.77, 0.33, 0.70 \t 0.72, 0.42, 0.62\n",
      "0.25 :\t 0.80, 0.37, 0.62 \t 0.73, 0.43, 0.57\n",
      "0.3 :\t 0.83, 0.40, 0.52 \t 0.81, 0.60, 0.48\n",
      "0.35 :\t 0.86, 0.47, 0.42 \t 0.83, 0.75, 0.36\n",
      "0.4 :\t 0.88, 0.64, 0.33 \t 0.84, 0.95, 0.33\n",
      "0.45 :\t 0.88, 0.61, 0.28 \t 0.83, 1.00, 0.28\n",
      "\n",
      "Our model looking at 3 unique words:\n",
      "0.0 :\t 0.14, 0.14, 1.00 \t 0.24, 0.23, 1.00\n",
      "0.05 :\t 0.54, 0.22, 0.97 \t 0.58, 0.35, 0.98\n",
      "0.1 :\t 0.69, 0.28, 0.86 \t 0.70, 0.43, 0.88\n",
      "0.15 :\t 0.75, 0.33, 0.78 \t 0.70, 0.40, 0.67\n",
      "0.2 :\t 0.77, 0.34, 0.71 \t 0.72, 0.43, 0.62\n",
      "0.25 :\t 0.81, 0.37, 0.62 \t 0.73, 0.43, 0.57\n",
      "0.3 :\t 0.83, 0.40, 0.51 \t 0.83, 0.66, 0.53\n",
      "0.35 :\t 0.85, 0.45, 0.42 \t 0.83, 0.74, 0.40\n",
      "0.4 :\t 0.89, 0.65, 0.35 \t 0.85, 0.95, 0.34\n",
      "0.45 :\t 0.88, 0.61, 0.28 \t 0.83, 1.00, 0.28\n",
      "\n",
      "Our model looking at 4 unique words:\n",
      "0.0 :\t 0.14, 0.14, 1.00 \t 0.24, 0.23, 1.00\n",
      "0.05 :\t 0.53, 0.22, 0.97 \t 0.58, 0.35, 0.98\n",
      "0.1 :\t 0.68, 0.28, 0.84 \t 0.70, 0.42, 0.84\n",
      "0.15 :\t 0.76, 0.33, 0.77 \t 0.70, 0.40, 0.67\n",
      "0.2 :\t 0.77, 0.34, 0.71 \t 0.72, 0.43, 0.62\n",
      "0.25 :\t 0.81, 0.37, 0.62 \t 0.73, 0.43, 0.57\n",
      "0.3 :\t 0.83, 0.39, 0.49 \t 0.82, 0.62, 0.53\n",
      "0.35 :\t 0.85, 0.46, 0.43 \t 0.83, 0.74, 0.40\n",
      "0.4 :\t 0.89, 0.65, 0.35 \t 0.84, 0.91, 0.34\n",
      "0.45 :\t 0.88, 0.61, 0.28 \t 0.83, 1.00, 0.28\n",
      "\n",
      "TF-IDF baseline\n",
      "Okapi BM25 baseline\n",
      "Always false\n",
      "training: 0.83, 0.00, 0.00 \t test: 0.84, 0.00, 0.00\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36-32\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "def test(y, y_hat):\n",
    "    #print(sklearn.metrics.r2_score(y, y_hat))\n",
    "    \n",
    "    \n",
    "    accuracy = sklearn.metrics.accuracy_score(y, y_hat)\n",
    "    precision = sklearn.metrics.precision_score(y, y_hat)\n",
    "    recall = sklearn.metrics.recall_score(y, y_hat)\n",
    "    \n",
    "    return \"{0:.2f}, {1:.2f}, {2:.2f}\".format(accuracy, precision, recall)\n",
    "\n",
    "def pipeline(X, y, breakpoint=0.15):\n",
    "    random.seed(4410)\n",
    "    \n",
    "    for j in range(0,len(X[0])):\n",
    "        featList = []\n",
    "        for i in range(0,len(X)-1):\n",
    "            featList.append(X[i][j])\n",
    "        featList = normalize(featList)\n",
    "        for i in range(0,len(X)-1):\n",
    "            X[i][j] = featList[i]\n",
    "    \n",
    "    keys = list(range(1, len(labels)))\n",
    "    points = dict(zip(keys, zip(X, y)))\n",
    "    random.shuffle(keys)\n",
    "    X_rand = [points[key][0] for key in keys]\n",
    "    y_rand = [points[key][1] for key in keys]\n",
    "    \n",
    "    X_train = X[:len(X_rand)*2//3]\n",
    "    y_train = y[:len(y_rand)*2//3]\n",
    "    \n",
    "    X_test = X[len(X_rand)*2//3:]\n",
    "    y_test = y[len(y_rand)*2//3:]\n",
    "       \n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_hatTrain = lr.predict(X_train)\n",
    "    y_hatTest = lr.predict(X_test)\n",
    "    \n",
    "    #print(X_train)\n",
    "    \n",
    "    #yesmean = 0\n",
    "    #yesnum = 0\n",
    "    #nomean = 0\n",
    "    #nonum = 0\n",
    "    #for elem, label in zip(y_hatTrain, y_train):\n",
    "    #    if label == 1:\n",
    "    #        yesmean = yesmean + elem\n",
    "    #        yesnum += 1\n",
    "    #    else:\n",
    "    #        nomean = nomean + elem\n",
    "    #        nonum += 1\n",
    "    #    #print(elem, \" \", label)\n",
    "    # \n",
    "    #print(yesmean, yesnum, nomean, nonum)\n",
    "    #point = ((yesmean / yesnum) + (nomean / nonum)) / 2\n",
    "    #print(point)\n",
    "    \n",
    "    return (y_hatTrain, y_hatTest, y_train, y_test)\n",
    "    \n",
    "    y_hatTrain = list(constrain(y_hatTrain, breakpoint))\n",
    "    y_hatTest = list(constrain(y_hatTest, breakpoint))\n",
    "    \n",
    "    # Test percentage that the top 3 relevant reviews are relevant.\n",
    "    for i in range(0, len(X) - 1):\n",
    "        x = X[i]\n",
    "        label = y[i]\n",
    "        pred = lr.predict([x])\n",
    "        review = data[i][\"review\"]\n",
    "        query = data[i][\"question\"]\n",
    "        \n",
    "        #print(label, pred, query, review)\n",
    "    \n",
    "    \n",
    "    train_string = test(y_train, y_hatTrain)\n",
    "    test_string = test(y_test, y_hatTest)\n",
    "    \n",
    "    print(train_string, \"\\t\", test_string, \"\\n\")\n",
    "    \n",
    "\n",
    "for length in range(0, 5):\n",
    "    print(\"Our model looking at\", length, \"unique words:\")\n",
    "    X = [feature(d[\"review\"], d[\"question\"], length) for d in data]\n",
    "    y = [1 if l == \"Y\" else 0 for l in labels]\n",
    "    y_hatTrain, y_hatTest, y_train, y_test = pipeline(X, y)\n",
    "    \n",
    "    for breakpoint in range(0, 10):\n",
    "    \n",
    "        y_hatTrain_c = list(constrain(y_hatTrain, breakpoint / 20))\n",
    "        y_hatTest_c = list(constrain(y_hatTest, breakpoint / 20))\n",
    "\n",
    "        train_string = test(y_train, y_hatTrain_c)\n",
    "        test_string = test(y_test, y_hatTest_c)\n",
    "\n",
    "        print(breakpoint / 20, \":\\t\", train_string, \"\\t\", test_string)\n",
    "    print()\n",
    "    \n",
    "\n",
    "\n",
    "print(\"TF-IDF baseline\")\n",
    "X = [feature_tfidf(d[\"review\"], d[\"question\"]) for d in data]\n",
    "y = [1 if l == \"Y\" else 0 for l in labels]\n",
    "pipeline(X, y)\n",
    "\n",
    "\n",
    "print(\"Okapi BM25 baseline\")\n",
    "X = [feature_okapi(d[\"review\"], d[\"question\"]) for d in data]\n",
    "y = [1 if l == \"Y\" else 0 for l in labels]\n",
    "pipeline(X, y)\n",
    "\n",
    "\n",
    "print(\"Always false\")\n",
    "random.seed(171727)\n",
    "y = [1 if l == \"Y\" else 0 for l in labels]\n",
    "keys = list(range(1, len(labels)))\n",
    "points = dict(zip(keys, zip(X, y)))\n",
    "random.shuffle(keys)\n",
    "y = [points[key][1] for key in keys]\n",
    "y_train = y[:len(y)//2]\n",
    "y_test = y[len(y)//2:]\n",
    "\n",
    "y_hatTrain = [0 for y in y_train]\n",
    "y_hatTest = [0 for y in y_test]\n",
    "\n",
    "train_string = test(y_train, y_hatTrain)\n",
    "test_string = test(y_test, y_hatTest)    \n",
    "print(\"training:\", train_string, \"\\t test:\", test_string)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
