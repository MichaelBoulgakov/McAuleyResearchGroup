{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import urllib\n",
    "import math\n",
    "import random\n",
    "import collections\n",
    "import string\n",
    "import csv\n",
    "import sys\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import svm\n",
    "import sklearn.metrics\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading labeled data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def parseLabeledData(path):\n",
    "    with open(path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.split(',')\n",
    "            yield({\"asin\":line[0],\n",
    "                 \"question\":line[1],\n",
    "                 \"review\":line[2],\n",
    "                 \"answer\":line[3].strip()\n",
    "                })\n",
    "        \n",
    "\n",
    "print(\"Reading labeled data...\")\n",
    "data = list(parseLabeledData(\"C:/Users/Moi/Downloads/highestReviewData.csv\"))\n",
    "#data = parseLabeledData(\"/Users/Silvia/Desktop/New Data - Sheet1.csv\")\n",
    "queries = [d['question'] for d in data]\n",
    "answers = [d['answer'] for d in data]\n",
    "reviews = [d['review'] for d in data]\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading all reviews & all questions...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def parseAllQueries(path):\n",
    "    file = open(path, 'r')\n",
    "    dataList = defaultdict(lambda: [])\n",
    "    for line in file:\n",
    "        line = eval(line)\n",
    "        dataList[line[\"asin\"]].append(line)\n",
    "      \n",
    "    return dataList\n",
    "\n",
    "def parseAllReviews(path):\n",
    "    file = open(path, 'r')\n",
    "    dataList = defaultdict(lambda: [])\n",
    "    for line in file:\n",
    "        line = eval(line)\n",
    "        dataList[line[\"asin\"]].append(line)\n",
    "      \n",
    "    return dataList\n",
    "\n",
    "print(\"Reading all reviews & all questions...\")\n",
    "\n",
    "allReviews = parseAllReviews(\"C:/Users/Moi/Downloads/reviews.json\")\n",
    "allQuestions = parseAllQueries(\"C:/Users/Moi/Downloads/qa.json\")\n",
    "\n",
    "#allReviews = parseAllReviews(\"/Users/Silvia/Downloads/reviews.json\")\n",
    "#allQuestions = parseAllQueries(\"/Users/Silvia/Downloads/qa.json\")\n",
    "\n",
    "# do we have to remove questions that have no reviews or reviews that have no questions??\n",
    "docSet = []\n",
    "for entry in allReviews.values():\n",
    "    for review in entry:\n",
    "        docSet.append(review[\"reviewText\"])\n",
    "\n",
    "for entry in allQuestions.values():\n",
    "    for question in entry:\n",
    "        docSet.append(question[\"question\"])\n",
    "\n",
    "docLen = [len(d.split()) for d in docSet]\n",
    "avgdl = sum(docLen) / len(docLen)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countAllWords():\n",
    "    allWords = defaultdict(int)\n",
    "    englishStopWords = stopwords.words('english')\n",
    "    for r in allReviews.values():\n",
    "        for review in r:\n",
    "            review = review[\"reviewText\"]\n",
    "            exclude = set(string.punctuation)\n",
    "            review = ''.join(ch for ch in review if ch not in exclude)\n",
    "            for w in review.lower().split():\n",
    "                if w not in englishStopWords:\n",
    "                    allWords[w] += 1\n",
    "\n",
    "    for q in allQuestions.values():\n",
    "        for question in q:\n",
    "            question = question[\"question\"]\n",
    "            exclude = set(string.punctuation)\n",
    "            question = ''.join(ch for ch in question if ch not in exclude)\n",
    "            for w in question.lower().split():\n",
    "                if w not in englishStopWords:\n",
    "                    allWords[w] += 1\n",
    "    \n",
    "    \n",
    "    return allWords\n",
    "\n",
    "allWords = countAllWords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonWords = sorted(allWords, key=lambda x: -allWords[x])[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordToIndex(term):\n",
    "    if term in commonWords:\n",
    "        return commonWords.index(term)\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwiseProduct(review, question, length):\n",
    "    reviewBag = [0]*length\n",
    "    questionBag = [0]*length\n",
    "    \n",
    "    exclude = set(string.punctuation)\n",
    "    review = ''.join(ch for ch in review if ch not in exclude)\n",
    "    question = ''.join(ch for ch in question if ch not in exclude)\n",
    "    \n",
    "    for term in review.lower().split():\n",
    "        index = wordToIndex(term)\n",
    "        \n",
    "        if index >= 0 and index < length:\n",
    "            reviewBag[index] = review.lower().split().count(term)\n",
    "        \n",
    "    for term in question.lower().split():\n",
    "        index = wordToIndex(term)\n",
    "        \n",
    "        if index >= 0 and index < length:\n",
    "            questionBag[index] = question.lower().split().count(term)\n",
    "        \n",
    "    bagFeat = [0]*length\n",
    "    \n",
    "    for i in range(0, length):\n",
    "        bagFeat[i] = reviewBag[i] * questionBag[i]\n",
    "        \n",
    "    #for i in range(0, length):\n",
    "        #if reviewBag[i] > 0 or questionBag[i] > 0:\n",
    "            #print(commonWords[i], reviewBag[i], questionBag[i], bagFeat[i])\n",
    "        \n",
    "    return bagFeat        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featForOnlyQuestion(question, length):\n",
    "    questionBag = [0]*length\n",
    "    \n",
    "    exclude = set(string.punctuation)\n",
    "    question = ''.join(ch for ch in question if ch not in exclude)\n",
    "        \n",
    "    for term in question.lower().split():\n",
    "        index = wordToIndex(term)\n",
    "        \n",
    "        if index >= 0 and index < length:\n",
    "            questionBag[index] = question.lower().split().count(term)\n",
    "        \n",
    "    #for i in range(0, length):\n",
    "        #if reviewBag[i] > 0 or questionBag[i] > 0:\n",
    "            #print(commonWords[i], reviewBag[i], questionBag[i], bagFeat[i])\n",
    "    \n",
    "   \n",
    "    return ([1]+questionBag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(featList):\n",
    "    \n",
    "    max = 0\n",
    "    min = float('inf')\n",
    "    for feat in featList:\n",
    "        if feat > max: max = feat\n",
    "        if feat < min: min = feat        \n",
    "    \n",
    "    for i in range(0,len(featList)-1):\n",
    "        if (max - min) == 0: \n",
    "            max = 1\n",
    "            min = 0\n",
    "        featList[i] = (featList[i] - min) / (max - min)\n",
    "\n",
    "    return featList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theLavFun(review, question):\n",
    "    feat = [1]\n",
    "    feat += pairwiseProduct(review, question, 1000)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y): \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X, y)\n",
    "    \n",
    "    return lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(y, y_hat):\n",
    "    #print(sklearn.metrics.r2_score(y, y_hat))\n",
    "    \n",
    "    \n",
    "    accuracy = sklearn.metrics.accuracy_score(y, y_hat)\n",
    "    precision = sklearn.metrics.precision_score(y, y_hat)\n",
    "    recall = sklearn.metrics.recall_score(y, y_hat)\n",
    "    \n",
    "    return \"{0:.2f}, {1:.2f}, {2:.2f}\".format(accuracy, precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constrain(elems, point):    \n",
    "    for elem in elems:\n",
    "        if (elem > point): yield 1\n",
    "        else: yield 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFeature(data):\n",
    "    for d in data:\n",
    "        yield(theLavFun(d[\"review\"], d[\"question\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(generateFeature(data))\n",
    "y = [1 if a == \"Y\" else 0 for a in answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(4410)\n",
    "\n",
    "keys = list(range(1, len(answers)))\n",
    "points = dict(zip(keys, zip(X, y)))\n",
    "random.shuffle(keys)\n",
    "X_rand = [points[key][0] for key in keys]\n",
    "y_rand = [points[key][1] for key in keys]\n",
    "\n",
    "X_train = X[:len(X_rand)*2//3]\n",
    "y_train = y[:len(y_rand)*2//3]\n",
    "\n",
    "X_test = X[len(X_rand)*2//3:]\n",
    "y_test = y[len(y_rand)*2//3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Yes!\n",
      "0.59, 0.59, 1.00\n",
      "0.50, 0.50, 1.00\n"
     ]
    }
   ],
   "source": [
    "y_hatTrain = lr.predict(X_train)\n",
    "y_hatTest = lr.predict(X_test)\n",
    "\n",
    "y_hatTrain = [1 for y_hat in y_hatTrain]\n",
    "y_hatTest = [1 for y_hat in y_hatTest]\n",
    "\n",
    "print(\"Predict Yes!\")\n",
    "print(test(y_train, y_hatTrain))\n",
    "print(test(y_test, y_hatTest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict with one question!\n",
      "-2.0 :\t 0.59, 0.59, 1.00 \t 0.55, 0.53, 1.00\n",
      "-1.9 :\t 0.59, 0.59, 1.00 \t 0.55, 0.53, 1.00\n",
      "-1.8 :\t 0.59, 0.59, 1.00 \t 0.55, 0.53, 1.00\n",
      "-1.7 :\t 0.59, 0.59, 1.00 \t 0.55, 0.53, 1.00\n",
      "-1.6 :\t 0.59, 0.59, 1.00 \t 0.55, 0.53, 1.00\n",
      "-1.5 :\t 0.59, 0.59, 1.00 \t 0.55, 0.53, 1.00\n",
      "-1.4 :\t 0.59, 0.59, 1.00 \t 0.55, 0.53, 1.00\n",
      "-1.3 :\t 0.59, 0.59, 1.00 \t 0.55, 0.53, 1.00\n",
      "-1.2 :\t 0.59, 0.59, 1.00 \t 0.58, 0.55, 1.00\n",
      "-1.1 :\t 0.59, 0.59, 1.00 \t 0.56, 0.53, 0.95\n",
      "-1.0 :\t 0.59, 0.59, 1.00 \t 0.56, 0.53, 0.95\n",
      "-0.9 :\t 0.59, 0.59, 1.00 \t 0.56, 0.53, 0.95\n",
      "-0.8 :\t 0.59, 0.59, 1.00 \t 0.56, 0.53, 0.95\n",
      "-0.7 :\t 0.59, 0.59, 1.00 \t 0.56, 0.53, 0.95\n",
      "-0.6 :\t 0.59, 0.59, 1.00 \t 0.59, 0.55, 0.95\n",
      "-0.5 :\t 0.59, 0.59, 1.00 \t 0.62, 0.57, 0.95\n",
      "-0.4 :\t 0.59, 0.59, 1.00 \t 0.62, 0.57, 0.95\n",
      "-0.3 :\t 0.59, 0.59, 1.00 \t 0.64, 0.58, 0.95\n",
      "-0.2 :\t 0.59, 0.59, 1.00 \t 0.64, 0.58, 0.95\n",
      "-0.1 :\t 0.59, 0.59, 1.00 \t 0.64, 0.58, 0.95\n",
      "0.0 :\t 0.73, 0.69, 1.00 \t 0.61, 0.57, 0.86\n",
      "0.1 :\t 1.00, 1.00, 1.00 \t 0.70, 0.65, 0.86\n",
      "0.2 :\t 1.00, 1.00, 1.00 \t 0.70, 0.66, 0.83\n",
      "0.3 :\t 1.00, 1.00, 1.00 \t 0.70, 0.66, 0.83\n",
      "0.4 :\t 1.00, 1.00, 1.00 \t 0.57, 0.58, 0.52\n",
      "0.5 :\t 1.00, 1.00, 1.00 \t 0.59, 0.61, 0.52\n",
      "0.6 :\t 1.00, 1.00, 1.00 \t 0.62, 0.66, 0.52\n",
      "0.7 :\t 1.00, 1.00, 1.00 \t 0.59, 0.63, 0.45\n",
      "0.8 :\t 1.00, 1.00, 1.00 \t 0.57, 0.61, 0.42\n",
      "0.9 :\t 1.00, 1.00, 1.00 \t 0.61, 0.69, 0.42\n",
      "1.0 :\t 0.65, 1.00, 0.41 \t 0.61, 0.69, 0.42\n",
      "1.1 :\t 0.41, 0.00, 0.00 \t 0.60, 0.67, 0.39\n",
      "1.2 :\t 0.41, 0.00, 0.00 \t 0.60, 0.67, 0.39\n",
      "1.3 :\t 0.41, 0.00, 0.00 \t 0.57, 0.64, 0.33\n",
      "1.4 :\t 0.41, 0.00, 0.00 \t 0.57, 0.64, 0.33\n",
      "1.5 :\t 0.41, 0.00, 0.00 \t 0.57, 0.64, 0.33\n",
      "1.6 :\t 0.41, 0.00, 0.00 \t 0.57, 0.64, 0.33\n",
      "1.7 :\t 0.41, 0.00, 0.00 \t 0.57, 0.64, 0.33\n",
      "1.8 :\t 0.41, 0.00, 0.00 \t 0.55, 0.61, 0.29\n",
      "1.9 :\t 0.41, 0.00, 0.00 \t 0.53, 0.57, 0.25\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36-64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Predict with one question!\")\n",
    "\n",
    "y_hatTrain = lr.predict(X_train)\n",
    "y_hatTest = lr.predict(X_test)\n",
    "\n",
    "for cutoff in range(-20, 20):\n",
    "    y_hatTrain_c = list(constrain(y_hatTrain, cutoff / 10))\n",
    "    y_hatTest_c = list(constrain(y_hatTest, cutoff / 10))\n",
    "    train_string = test(y_train, y_hatTrain_c)\n",
    "    test_string = test(y_test, y_hatTest_c)\n",
    "\n",
    "    print(cutoff / 10, \":\\t\", train_string, \"\\t\", test_string)\n",
    "\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict with one question and the most relevant review!\n",
      "-2.0 :\t 0.69, 0.69, 1.00 \t 0.61, 0.64, 0.74\n",
      "-1.9 :\t 0.69, 0.69, 1.00 \t 0.61, 0.64, 0.74\n",
      "-1.8 :\t 0.69, 0.69, 1.00 \t 0.61, 0.64, 0.74\n",
      "-1.7 :\t 0.69, 0.69, 1.00 \t 0.61, 0.64, 0.74\n",
      "-1.6 :\t 0.69, 0.69, 1.00 \t 0.61, 0.64, 0.74\n",
      "-1.5 :\t 0.69, 0.69, 1.00 \t 0.61, 0.64, 0.74\n",
      "-1.4 :\t 0.69, 0.69, 1.00 \t 0.59, 0.64, 0.72\n",
      "-1.3 :\t 0.69, 0.69, 1.00 \t 0.59, 0.64, 0.72\n",
      "-1.2 :\t 0.69, 0.69, 1.00 \t 0.59, 0.64, 0.72\n",
      "-1.1 :\t 0.69, 0.69, 1.00 \t 0.59, 0.64, 0.72\n",
      "-1.0 :\t 0.69, 0.69, 1.00 \t 0.59, 0.64, 0.72\n",
      "-0.9 :\t 0.69, 0.69, 1.00 \t 0.59, 0.64, 0.72\n",
      "-0.8 :\t 0.69, 0.69, 1.00 \t 0.59, 0.64, 0.72\n",
      "-0.7 :\t 0.69, 0.69, 1.00 \t 0.59, 0.64, 0.72\n",
      "-0.6 :\t 0.69, 0.69, 1.00 \t 0.59, 0.64, 0.72\n",
      "-0.5 :\t 0.69, 0.69, 1.00 \t 0.59, 0.64, 0.72\n",
      "-0.4 :\t 0.69, 0.69, 1.00 \t 0.61, 0.65, 0.72\n",
      "-0.3 :\t 0.69, 0.69, 1.00 \t 0.61, 0.65, 0.72\n",
      "-0.2 :\t 0.69, 0.69, 1.00 \t 0.61, 0.65, 0.72\n",
      "-0.1 :\t 0.70, 0.70, 1.00 \t 0.61, 0.65, 0.72\n",
      "0.0 :\t 0.82, 0.79, 1.00 \t 0.61, 0.65, 0.72\n",
      "0.1 :\t 0.91, 0.88, 1.00 \t 0.61, 0.65, 0.72\n",
      "0.2 :\t 0.91, 0.88, 1.00 \t 0.62, 0.67, 0.72\n",
      "0.3 :\t 0.91, 0.88, 1.00 \t 0.62, 0.67, 0.72\n",
      "0.4 :\t 0.92, 0.89, 1.00 \t 0.62, 0.67, 0.72\n",
      "0.5 :\t 0.92, 0.89, 1.00 \t 0.62, 0.68, 0.69\n",
      "0.6 :\t 0.90, 0.99, 0.87 \t 0.52, 0.65, 0.38\n",
      "0.7 :\t 0.90, 1.00, 0.86 \t 0.52, 0.65, 0.38\n",
      "0.8 :\t 0.88, 1.00, 0.83 \t 0.48, 0.62, 0.33\n",
      "0.9 :\t 0.87, 1.00, 0.81 \t 0.47, 0.60, 0.31\n",
      "1.0 :\t 0.57, 1.00, 0.38 \t 0.45, 0.58, 0.28\n",
      "1.1 :\t 0.32, 1.00, 0.02 \t 0.44, 0.56, 0.26\n",
      "1.2 :\t 0.32, 1.00, 0.01 \t 0.45, 0.59, 0.26\n",
      "1.3 :\t 0.31, 0.00, 0.00 \t 0.45, 0.59, 0.26\n",
      "1.4 :\t 0.31, 0.00, 0.00 \t 0.45, 0.59, 0.26\n",
      "1.5 :\t 0.31, 0.00, 0.00 \t 0.45, 0.59, 0.26\n",
      "1.6 :\t 0.31, 0.00, 0.00 \t 0.45, 0.59, 0.26\n",
      "1.7 :\t 0.31, 0.00, 0.00 \t 0.45, 0.59, 0.26\n",
      "1.8 :\t 0.31, 0.00, 0.00 \t 0.45, 0.59, 0.26\n",
      "1.9 :\t 0.31, 0.00, 0.00 \t 0.45, 0.59, 0.26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36-64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Predict with one question and the most relevant review!\")\n",
    "\n",
    "y_hatTrain = lr.predict(X_train)\n",
    "y_hatTest = lr.predict(X_test)\n",
    "\n",
    "for cutoff in range(-20, 20):\n",
    "    y_hatTrain_c = list(constrain(y_hatTrain, cutoff / 10))\n",
    "    y_hatTest_c = list(constrain(y_hatTest, cutoff / 10))\n",
    "    train_string = test(y_train, y_hatTrain_c)\n",
    "    test_string = test(y_test, y_hatTest_c)\n",
    "\n",
    "    print(cutoff / 10, \":\\t\", train_string, \"\\t\", test_string)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
