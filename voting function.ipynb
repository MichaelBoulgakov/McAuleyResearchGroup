{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import urllib\n",
    "import math\n",
    "import random\n",
    "import collections\n",
    "import string\n",
    "import csv\n",
    "import sys\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import svm\n",
    "import sklearn.metrics\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading labeled data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def parseLabeledData(path):\n",
    "    with open(path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.split(',')\n",
    "            yield({\"asin\":line[0],\n",
    "                 \"question\":line[1],\n",
    "                 \"review\":line[2],\n",
    "                 \"answer\":line[3],\n",
    "                 \"relevance\":float(line[4])\n",
    "                })\n",
    "        \n",
    "\n",
    "print(\"Reading labeled data...\")\n",
    "data = list(parseLabeledData(\"C:/Users/Moi/Downloads/highestReviewData.csv\"))\n",
    "#data = parseLabeledData(\"/Users/Silvia/Desktop/New Data - Sheet1.csv\")\n",
    "asins = [d['asin'] for d in data]\n",
    "queries = [d['question'] for d in data]\n",
    "reviews = [d['review'] for d in data]\n",
    "answers = [d['answer'] for d in data]\n",
    "relevances = [d['relevance'] for d in data]\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading all reviews & all questions...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def parseAllQueries(path):\n",
    "    file = open(path, 'r')\n",
    "    dataList = defaultdict(lambda: [])\n",
    "    for line in file:\n",
    "        line = eval(line)\n",
    "        dataList[line[\"asin\"]].append(line)\n",
    "      \n",
    "    return dataList\n",
    "\n",
    "def parseAllReviews(path):\n",
    "    file = open(path, 'r')\n",
    "    dataList = defaultdict(lambda: [])\n",
    "    for line in file:\n",
    "        line = eval(line)\n",
    "        dataList[line[\"asin\"]].append(line)\n",
    "      \n",
    "    return dataList\n",
    "\n",
    "print(\"Reading all reviews & all questions...\")\n",
    "\n",
    "allReviews = parseAllReviews(\"C:/Users/Moi/Downloads/reviews.json\")\n",
    "allQuestions = parseAllQueries(\"C:/Users/Moi/Downloads/qa.json\")\n",
    "\n",
    "#allReviews = parseAllReviews(\"/Users/Silvia/Downloads/reviews.json\")\n",
    "#allQuestions = parseAllQueries(\"/Users/Silvia/Downloads/qa.json\")\n",
    "\n",
    "# do we have to remove questions that have no reviews or reviews that have no questions??\n",
    "docSet = []\n",
    "for entry in allReviews.values():\n",
    "    for review in entry:\n",
    "        docSet.append(review[\"reviewText\"])\n",
    "\n",
    "for entry in allQuestions.values():\n",
    "    for question in entry:\n",
    "        docSet.append(question[\"question\"])\n",
    "\n",
    "docLen = [len(d.split()) for d in docSet]\n",
    "avgdl = sum(docLen) / len(docLen)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countAllWords():\n",
    "    allWords = defaultdict(int)\n",
    "    englishStopWords = stopwords.words('english')\n",
    "    for r in allReviews.values():\n",
    "        for review in r:\n",
    "            review = review[\"reviewText\"]\n",
    "            exclude = set(string.punctuation)\n",
    "            review = ''.join(ch for ch in review if ch not in exclude)\n",
    "            for w in review.lower().split():\n",
    "                if w not in englishStopWords:\n",
    "                    allWords[w] += 1\n",
    "\n",
    "    for q in allQuestions.values():\n",
    "        for question in q:\n",
    "            question = question[\"question\"]\n",
    "            exclude = set(string.punctuation)\n",
    "            question = ''.join(ch for ch in question if ch not in exclude)\n",
    "            for w in question.lower().split():\n",
    "                if w not in englishStopWords:\n",
    "                    allWords[w] += 1\n",
    "    \n",
    "    \n",
    "    return allWords\n",
    "\n",
    "allWords = countAllWords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonWords = sorted(allWords, key=lambda x: -allWords[x])[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordToIndex(term):\n",
    "    if term in commonWords:\n",
    "        return commonWords.index(term)\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagCache = {}\n",
    "\n",
    "def bagOfWords(document, length):\n",
    "    if (document, length) in bagCache:\n",
    "        return bagCache[(document, length)]\n",
    "    \n",
    "    bag = [0]*length\n",
    "    \n",
    "    exclude = set(string.punctuation)\n",
    "    doc = ''.join(ch for ch in document if ch not in exclude)\n",
    "    doc = doc.lower().split()\n",
    "    \n",
    "    for term in doc:\n",
    "        index = wordToIndex(term)\n",
    "        \n",
    "        if index >= 0 and index < length:\n",
    "            bag[index] = doc.count(term)\n",
    "            \n",
    "    bagCache[(document, length)] = bag\n",
    "    \n",
    "    return bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwiseProduct(review, question, length):\n",
    "    reviewBag = bagOfWords(review, length)\n",
    "    questionBag = bagOfWords(question, length)\n",
    "        \n",
    "    bagFeat = [0]*length\n",
    "    \n",
    "    for i in range(0, length):\n",
    "        bagFeat[i] = reviewBag[i] * questionBag[i]\n",
    "        \n",
    "    #for i in range(0, length):\n",
    "        #if reviewBag[i] > 0 or questionBag[i] > 0:\n",
    "            #print(commonWords[i], reviewBag[i], questionBag[i], bagFeat[i])\n",
    "        \n",
    "    return bagFeat        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featForOnlyQuestion(question, length):\n",
    "    return ([1]+bagOfWords(question, length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featForQuestionAndRelevantReview(review, question):\n",
    "    feat = [1]\n",
    "    feat += pairwiseProduct(review, question, 500)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(featList):\n",
    "    \n",
    "    max = 0\n",
    "    min = float('inf')\n",
    "    for feat in featList:\n",
    "        if feat > max: max = feat\n",
    "        if feat < min: min = feat        \n",
    "    \n",
    "    for i in range(0,len(featList)-1):\n",
    "        if (max - min) == 0: \n",
    "            max = 1\n",
    "            min = 0\n",
    "        featList[i] = (featList[i] - min) / (max - min)\n",
    "\n",
    "    return featList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y): \n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X, y)\n",
    "    \n",
    "    return lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(y, y_hat):\n",
    "    #print(sklearn.metrics.r2_score(y, y_hat))\n",
    "    \n",
    "    \n",
    "    accuracy = sklearn.metrics.accuracy_score(y, y_hat)\n",
    "    precision = sklearn.metrics.precision_score(y, y_hat)\n",
    "    recall = sklearn.metrics.recall_score(y, y_hat)\n",
    "    \n",
    "    return \"{0:.2f}, {1:.2f}, {2:.2f}\".format(accuracy, precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constrain(elems, point):    \n",
    "    for elem in elems:\n",
    "        if (elem > point): yield 1\n",
    "        else: yield 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1896\n"
     ]
    }
   ],
   "source": [
    "random.seed(505)\n",
    "\n",
    "thresh = 0.5\n",
    "\n",
    "yesPoint = [(featForQuestionAndRelevantReview(d[\"review\"], d[\"question\"]), 1 if d[\"answer\"] == \"Y\" else 0, i)\n",
    "            for d, i in zip(data, range(0, len(data))) if d[\"answer\"] == \"Y\" and d[\"relevance\"] > thresh]\n",
    "noPoint  = [(featForQuestionAndRelevantReview(d[\"review\"], d[\"question\"]), 1 if d[\"answer\"] == \"Y\" else 0, i)\n",
    "            for d, i in zip(data, range(0, len(data))) if d[\"answer\"] == \"N\" and d[\"relevance\"] > thresh]\n",
    "\n",
    "#yesPoint = [(featForOnlyQuestion(d[\"question\"], 1000), 1 if d[\"answer\"] == \"Y\" else 0, i)\n",
    "#            for d, i in zip(data, range(0, len(data))) if d[\"answer\"] == \"Y\" and d[\"relevance\"] > thresh]\n",
    "#noPoint  = [(featForOnlyQuestion(d[\"question\"], 1000), 1 if d[\"answer\"] == \"Y\" else 0, i)\n",
    "#            for d, i in zip(data, range(0, len(data))) if d[\"answer\"] == \"N\" and d[\"relevance\"] > thresh]\n",
    "\n",
    "#yesPoint = random.sample(yesPoint, len(noPoint))\n",
    "\n",
    "points = yesPoint + noPoint\n",
    "random.shuffle(points)\n",
    "\n",
    "X = [p[0] for p in points]\n",
    "y = [p[1] for p in points]\n",
    "i = [p[2] for p in points]\n",
    "\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1264 1264 632 632\n"
     ]
    }
   ],
   "source": [
    "X_train = X[:len(X)*2//3]\n",
    "y_train = y[:len(X)*2//3]\n",
    "i_train = i[:len(X)*2//3]\n",
    "\n",
    "X_test = X[len(X)*2//3:]\n",
    "y_test = y[len(X)*2//3:]\n",
    "\n",
    "#X_test = [featForQuestionAndRelevantReview(d[\"review\"], d[\"question\"]) for d in data]\n",
    "#y_test = [1 if d[\"answer\"] == \"Y\" else 0 for d in data]\n",
    "#i_test = list(range(0, len(data)))\n",
    "                                           \n",
    "print(len(X_train), len(y_train), len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict with one question and the most relevant review!\n",
      "0.0 :\t 0.80, 0.80, 1.00 \t 0.80, 0.80, 1.00\n",
      "0.05 :\t 0.80, 0.80, 1.00 \t 0.79, 0.80, 0.99\n",
      "0.1 :\t 0.81, 0.81, 1.00 \t 0.79, 0.80, 0.99\n",
      "0.15 :\t 0.81, 0.81, 1.00 \t 0.79, 0.80, 0.98\n",
      "0.2 :\t 0.81, 0.81, 1.00 \t 0.79, 0.80, 0.98\n",
      "0.25 :\t 0.82, 0.82, 1.00 \t 0.79, 0.80, 0.98\n",
      "0.3 :\t 0.83, 0.82, 1.00 \t 0.78, 0.80, 0.97\n",
      "0.35 :\t 0.83, 0.83, 1.00 \t 0.78, 0.80, 0.96\n",
      "0.4 :\t 0.83, 0.83, 1.00 \t 0.78, 0.81, 0.96\n",
      "0.45 :\t 0.84, 0.84, 0.99 \t 0.78, 0.81, 0.95\n",
      "0.5 :\t 0.84, 0.84, 0.99 \t 0.78, 0.81, 0.95\n",
      "0.55 :\t 0.85, 0.85, 0.98 \t 0.78, 0.82, 0.94\n",
      "0.6 :\t 0.86, 0.87, 0.98 \t 0.78, 0.82, 0.93\n",
      "0.65 :\t 0.86, 0.87, 0.96 \t 0.78, 0.83, 0.90\n",
      "0.7 :\t 0.86, 0.88, 0.95 \t 0.78, 0.84, 0.88\n",
      "0.75 :\t 0.83, 0.89, 0.89 \t 0.75, 0.86, 0.83\n",
      "0.8 :\t 0.75, 0.90, 0.78 \t 0.70, 0.87, 0.73\n",
      "0.85 :\t 0.55, 0.98, 0.44 \t 0.50, 0.92, 0.41\n",
      "0.9 :\t 0.44, 1.00, 0.30 \t 0.39, 0.93, 0.26\n",
      "0.95 :\t 0.34, 1.00, 0.17 \t 0.32, 0.92, 0.16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Predict with one question and the most relevant review!\")\n",
    "\n",
    "y_hatTrain = [p[1] for p in lr.predict_proba(X_train)]\n",
    "y_hatTest  = [p[1] for p in lr.predict_proba(X_test)]\n",
    "\n",
    "#y_hatTrain = [p[1] for i, p in zip(i_train, lr.predict_proba(X_train)) if relevances[i] > thresh]\n",
    "#y_hatTest  = [p[1] for i, p in zip(i_test, lr.predict_proba(X_test))  if relevances[i] > thresh]\n",
    "\n",
    "y_train_r = [p for i, p in zip(i_train, y_train) if relevances[i] > thresh]\n",
    "y_test_r  = [p for i, p in zip(i_test, y_test)  if relevances[i] > thresh]\n",
    "\n",
    "for cutoff in range(0, 20):\n",
    "    y_hatTrain_c = list(constrain(y_hatTrain, cutoff / 20))\n",
    "    y_hatTest_c = list(constrain(y_hatTest, cutoff / 20))\n",
    "    #print(len(y_hatTest_c), len(y_hatTest), len(X_test), len(y_test))\n",
    "    train_string = test(y_train, y_hatTrain_c)\n",
    "    test_string = test(y_test, y_hatTest_c)\n",
    "\n",
    "    print(cutoff / 20, \":\\t\", train_string, \"\\t\", test_string)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featForQuestionAndReviews(reviews, relevances, question):    \n",
    "    feat = [1]\n",
    "    \n",
    "    reviewBag = [0]*500\n",
    "    \n",
    "    totalRelevance = sum(relevances)\n",
    "    \n",
    "    for (review, relevance) in zip(reviews, relevances):\n",
    "        bow = bagOfWords(review, 500)\n",
    "        reviewBag = [x + y * relevance / totalRelevance for x, y in zip(reviewBag, bow)]\n",
    "\n",
    "    questionBag = bagOfWords(question, 500)\n",
    "    \n",
    "    bagFeat = [0]*500\n",
    "    \n",
    "    for i in range(0, 500):\n",
    "        bagFeat[i] = reviewBag[i] * questionBag[i]\n",
    "    \n",
    "    feat += bagFeat\n",
    "    \n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "924\n"
     ]
    }
   ],
   "source": [
    "random.seed(505)\n",
    "\n",
    "thresh = 0.5\n",
    "\n",
    "yesPoint = []\n",
    "noPoint = []\n",
    "\n",
    "i = 0\n",
    "while i < len(data):\n",
    "    highestSoFar = 0\n",
    "    \n",
    "    qReviews = []\n",
    "    qRelevances = []\n",
    "\n",
    "    question = data[i][\"question\"]\n",
    "    answer = data[i][\"answer\"]\n",
    "    \n",
    "    while (i < len(data) and data[i][\"question\"] == question):        \n",
    "        if (data[i][\"relevance\"] > thresh):\n",
    "            highestSoFar = data[i][\"relevance\"]\n",
    "            qReviews += [data[i][\"review\"]]\n",
    "            qRelevances += [data[i][\"relevance\"]]\n",
    "        i += 1\n",
    "    \n",
    "    if (answer == \"Y\" and highestSoFar != 0):\n",
    "        yesPoint += [(featForQuestionAndReviews(qReviews, qRelevances, question), 1)]\n",
    "    elif (highestSoFar != 0):\n",
    "        noPoint  += [(featForQuestionAndReviews(qReviews, qRelevances, question), 0)]\n",
    "\n",
    "#yesPoint = [(featForQuestionAndReviews(d[\"review\"], d[\"question\"]), 1 if d[\"answer\"] == \"Y\" else 0, i)\n",
    "#            for d, i in zip(data, range(0, len(data))) if d[\"answer\"] == \"Y\" and d[\"relevance\"] > 0.5]\n",
    "#noPoint  = [(featForQuestionAndReviews(d[\"review\"], d[\"question\"]), 1 if d[\"answer\"] == \"Y\" else 0, i)\n",
    "#            for d, i in zip(data, range(0, len(data))) if d[\"answer\"] == \"N\" and d[\"relevance\"] > 0.5]\n",
    "\n",
    "#yesPoint = random.sample(yesPoint, len(noPoint))\n",
    "\n",
    "points = yesPoint + noPoint\n",
    "random.shuffle(points)\n",
    "\n",
    "X = [p[0] for p in points]\n",
    "y = [p[1] for p in points]\n",
    "\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "616 616 308 308\n"
     ]
    }
   ],
   "source": [
    "X_train = X[:len(X)*2//3]\n",
    "y_train = y[:len(X)*2//3]\n",
    "\n",
    "X_test = X[len(X)*2//3:]\n",
    "y_test = y[len(X)*2//3:]\n",
    "\n",
    "print(len(X_train), len(y_train), len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict with one question and all the most relevant review!\n",
      "0.0 :\t 0.78, 0.78, 1.00 \t 0.76, 0.76, 1.00\n",
      "0.05 :\t 0.78, 0.78, 1.00 \t 0.76, 0.76, 1.00\n",
      "0.1 :\t 0.78, 0.78, 1.00 \t 0.76, 0.76, 1.00\n",
      "0.15 :\t 0.78, 0.78, 1.00 \t 0.76, 0.76, 1.00\n",
      "0.2 :\t 0.78, 0.78, 1.00 \t 0.76, 0.76, 1.00\n",
      "0.25 :\t 0.78, 0.78, 1.00 \t 0.76, 0.76, 1.00\n",
      "0.3 :\t 0.78, 0.78, 1.00 \t 0.76, 0.76, 1.00\n",
      "0.35 :\t 0.78, 0.78, 1.00 \t 0.76, 0.76, 1.00\n",
      "0.4 :\t 0.78, 0.78, 1.00 \t 0.76, 0.76, 1.00\n",
      "0.45 :\t 0.78, 0.78, 1.00 \t 0.76, 0.76, 1.00\n",
      "0.5 :\t 0.78, 0.78, 1.00 \t 0.76, 0.76, 1.00\n",
      "0.55 :\t 0.78, 0.78, 1.00 \t 0.76, 0.76, 1.00\n",
      "0.6 :\t 0.78, 0.78, 1.00 \t 0.76, 0.76, 1.00\n",
      "0.65 :\t 0.78, 0.78, 1.00 \t 0.76, 0.76, 1.00\n",
      "0.7 :\t 0.78, 0.78, 1.00 \t 0.76, 0.76, 1.00\n",
      "0.75 :\t 0.78, 0.78, 1.00 \t 0.76, 0.76, 1.00\n",
      "0.8 :\t 0.78, 0.78, 1.00 \t 0.76, 0.76, 1.00\n",
      "0.85 :\t 0.78, 0.78, 1.00 \t 0.76, 0.76, 1.00\n",
      "0.9 :\t 0.78, 0.78, 1.00 \t 0.76, 0.76, 1.00\n",
      "0.95 :\t 0.78, 0.78, 1.00 \t 0.76, 0.76, 1.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Predict with one question and all the most relevant review!\")\n",
    "\n",
    "y_hatTrain = [p[1] for p in lr.predict_proba(X_train)]\n",
    "y_hatTest  = [p[1] for p in lr.predict_proba(X_test)]\n",
    "\n",
    "for cutoff in range(0, 20):\n",
    "    y_hatTrain_c = list(constrain(y_hatTrain, cutoff / 20))\n",
    "    y_hatTest_c = list(constrain(y_hatTest, cutoff / 20))\n",
    "    train_string = test(y_train, y_hatTrain_c)\n",
    "    test_string = test(y_test, y_hatTest_c)\n",
    "\n",
    "    print(cutoff / 20, \":\\t\", train_string, \"\\t\", test_string)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
